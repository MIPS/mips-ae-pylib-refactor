{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e539b14",
   "metadata": {},
   "source": [
    "# Atlas Explorer 3.0 - Multicore Performance Analysis\n",
    "\n",
    "This notebook demonstrates **multicore CPU performance analysis** using the Atlas Explorer 3.0 modular architecture.\n",
    "\n",
    "## Learning Objectives\n",
    "- Configure Atlas Explorer for multicore analysis\n",
    "- Execute parallel workloads across multiple threads\n",
    "- Analyze thread load balancing and scaling efficiency\n",
    "- Understand resource contention and cache sharing\n",
    "- Generate advanced multicore optimization insights\n",
    "\n",
    "## Prerequisites\n",
    "- Atlas Explorer credentials configured (`atlasexplorer configure`)\n",
    "- Package installed with notebook dependencies (`uv pip install -e '.[notebooks]'`)\n",
    "- Familiarity with single-core analysis (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries for Multicore Analysis\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Atlas Explorer 3.0 modular imports\n",
    "from atlasexplorer.core.client import AtlasExplorer\n",
    "from atlasexplorer.core.experiment import Experiment\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Atlas Explorer 3.0 - Ready for multicore analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b319904",
   "metadata": {},
   "source": [
    "## Configuration Check\n",
    "\n",
    "Let's verify that your Atlas Explorer credentials are properly configured for multicore experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e8ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Atlas Explorer Configuration for Multicore\n",
    "print(\"Checking Atlas Explorer Configuration for Multicore...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Initialize Atlas Explorer client\n",
    "    ae = AtlasExplorer(channel=\"development\", verbose=True)\n",
    "    \n",
    "    print(\"Configuration Status: READY FOR MULTICORE\")\n",
    "    print(f\"Gateway: {ae.config.gateway}\")\n",
    "    print(f\"Channel: {ae.config.channel}\")\n",
    "    print(f\"Region: {ae.config.region}\")\n",
    "    print(f\"API Key: {ae.config.apikey[:8]}...\")\n",
    "    print(\"Ready for parallel computing analysis!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Configuration Error:\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nTo fix this, run: atlasexplorer configure\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b513e7a",
   "metadata": {},
   "source": [
    "## Experiment History\n",
    "\n",
    "Let's check your previous experiments to see any multicore analysis history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744451f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Previous Multicore Experiments\n",
    "print(\"Previous Atlas Explorer Experiments:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "experiment_dir = Path(\"myexperiments\")\n",
    "experiments = []\n",
    "\n",
    "if experiment_dir.exists():\n",
    "    for exp_path in experiment_dir.iterdir():\n",
    "        if exp_path.is_dir():\n",
    "            config_file = exp_path / \"config.json\"\n",
    "            if config_file.exists():\n",
    "                try:\n",
    "                    with open(config_file) as f:\n",
    "                        config = json.load(f)\n",
    "                    \n",
    "                    mod_time = datetime.fromtimestamp(exp_path.stat().st_mtime)\n",
    "                    core_config = config.get(\"core\", \"unknown\")\n",
    "                    \n",
    "                    experiments.append({\n",
    "                        \"Experiment\": exp_path.name,\n",
    "                        \"Channel\": config.get(\"channel\", \"unknown\"),\n",
    "                        \"Core\": core_config,\n",
    "                        \"Type\": \"Multicore\" if \"thread\" in core_config and not \"1_thread\" in core_config else \"Single-core\",\n",
    "                        \"Modified\": mod_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    })\n",
    "                except (json.JSONDecodeError, KeyError):\n",
    "                    continue\n",
    "\n",
    "if experiments:\n",
    "    df = pd.DataFrame(experiments).sort_values(\"Modified\", ascending=False)\n",
    "    display(df)\n",
    "    \n",
    "    multicore_count = sum(1 for exp in experiments if \"Multicore\" in exp[\"Type\"])\n",
    "    print(f\"\\nFound {len(experiments)} total experiments ({multicore_count} multicore)\")\n",
    "else:\n",
    "    print(\"No previous experiments found. This will be your first multicore experiment!\")\n",
    "    print(\"Creating 'myexperiments' directory for results...\")\n",
    "    experiment_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be22f3d",
   "metadata": {},
   "source": [
    "## Multicore Experiment Setup\n",
    "\n",
    "Now let's set up a multicore experiment using multiple workloads to analyze parallel performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb518e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multicore Experiment Configuration\n",
    "print(\"Setting up Multicore Performance Experiment\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Experiment parameters\n",
    "elf_files = [\n",
    "    \"resources/mandelbrot_rv64_O0.elf\",\n",
    "    \"resources/memcpy_rv64.elf\"\n",
    "]\n",
    "core_config = \"I8500_(2_threads)\"  # 2-core configuration\n",
    "experiment_name = \"multicore_parallel_analysis\"\n",
    "results_dir = \"myexperiments\"\n",
    "\n",
    "print(f\"ELF Files:\")\n",
    "for i, elf_file in enumerate(elf_files, 1):\n",
    "    print(f\"   {i}. {elf_file}\")\n",
    "print(f\"Core Configuration: {core_config}\")\n",
    "print(f\"Experiment Name: {experiment_name}\")\n",
    "print(f\"Results Directory: {results_dir}\")\n",
    "\n",
    "# Verify all ELF files exist\n",
    "missing_files = []\n",
    "for elf_file in elf_files:\n",
    "    if not os.path.exists(elf_file):\n",
    "        missing_files.append(elf_file)\n",
    "    else:\n",
    "        print(f\"Verified: {elf_file}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"Error: Missing ELF files: {missing_files}\")\n",
    "    print(\"Make sure you're running from the repository root directory\")\n",
    "    raise FileNotFoundError(f\"ELF files not found: {missing_files}\")\n",
    "    \n",
    "print(\"\\nReady to launch multicore experiment!\")\n",
    "print(f\"This will analyze parallel execution across {core_config.split('_')[1].replace('(', '').replace(')', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c9aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch Multicore Experiment\n",
    "print(\"Launching Multicore Performance Analysis...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Create experiment\n",
    "    experiment = Experiment(experiment_name, ae)\n",
    "    \n",
    "    # Configure experiment with multiple workloads\n",
    "    for elf_file in elf_files:\n",
    "        experiment.addWorkload(elf_file)\n",
    "    \n",
    "    experiment.setCore(core_config)\n",
    "    experiment.setResultsDir(results_dir)\n",
    "    \n",
    "    print(f\"Multicore experiment configured:\")\n",
    "    print(f\"   Name: {experiment_name}\")\n",
    "    print(f\"   Workloads: {len(elf_files)} parallel tasks\")\n",
    "    for i, elf_file in enumerate(elf_files, 1):\n",
    "        print(f\"     {i}. {os.path.basename(elf_file)}\")\n",
    "    print(f\"   Core: {core_config}\")\n",
    "    print(f\"   Channel: {ae.config.channel}\")\n",
    "    \n",
    "    # Run experiment\n",
    "    print(\"\\nRunning multicore experiment... (this may take 2-5 minutes)\")\n",
    "    print(\"Analyzing parallel execution, thread load balancing, and resource sharing...\")\n",
    "    experiment.run()\n",
    "    \n",
    "    print(\"\\nMulticore experiment completed successfully!\")\n",
    "    print(f\"Results saved to: {results_dir}/{experiment_name}/\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Experiment failed: {e}\")\n",
    "    print(\"Check your network connection and credentials\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067da4a",
   "metadata": {},
   "source": [
    "## Multicore Performance Results\n",
    "\n",
    "Now let's analyze the parallel performance results and thread efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and Display Multicore Performance Metrics\n",
    "print(\"MULTICORE PERFORMANCE ANALYSIS RESULTS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Get experiment summary\n",
    "summary = experiment.getSummary()\n",
    "\n",
    "# Overall performance metrics\n",
    "total_cycles = summary.getTotalCycles()\n",
    "total_instructions = summary.getTotalInstructions()\n",
    "combined_ipc = summary.getIPC()\n",
    "l1_icache_hit_rate = summary.getL1InstructionCacheHitRate()\n",
    "l1_dcache_hit_rate = summary.getL1DataCacheHitRate()\n",
    "\n",
    "print(f\"OVERALL MULTICORE RESULTS:\")\n",
    "print(f\"   Total Cycles: {total_cycles:,}\")\n",
    "print(f\"   Instructions Executed: {total_instructions:,}\")\n",
    "print(f\"   Combined IPC: {combined_ipc:.3f}\")\n",
    "print(f\"\\nSHARED CACHE PERFORMANCE:\")\n",
    "print(f\"   L1 Instruction Cache Hit Rate: {l1_icache_hit_rate:.2f}%\")\n",
    "print(f\"   L1 Data Cache Hit Rate: {l1_dcache_hit_rate:.2f}%\")\n",
    "\n",
    "# Try to get per-thread metrics if available\n",
    "print(f\"\\nTHREAD-LEVEL ANALYSIS:\")\n",
    "try:\n",
    "    # This may vary depending on the exact API\n",
    "    thread_metrics = summary.getThreadMetrics() if hasattr(summary, 'getThreadMetrics') else None\n",
    "    if thread_metrics:\n",
    "        for i, thread in enumerate(thread_metrics):\n",
    "            print(f\"   Thread {i}: {thread['instructions']:,} instructions, IPC: {thread['ipc']:.3f}\")\n",
    "    else:\n",
    "        # Estimate thread distribution\n",
    "        estimated_instructions_per_thread = total_instructions // len(elf_files)\n",
    "        estimated_ipc_per_thread = combined_ipc / len(elf_files)\n",
    "        \n",
    "        for i in range(len(elf_files)):\n",
    "            print(f\"   Thread {i} (estimated): ~{estimated_instructions_per_thread:,} instructions, IPC: ~{estimated_ipc_per_thread:.3f}\")\n",
    "        print(f\"   Note: Per-thread metrics estimated from combined results\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   Warning: Individual thread metrics not available: {e}\")\n",
    "    print(f\"   Combined metrics shown above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5caab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel Efficiency Analysis\n",
    "print(\"PARALLEL EFFICIENCY & SCALING ANALYSIS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Calculate parallel efficiency metrics\n",
    "num_cores = len(elf_files)\n",
    "theoretical_max_ipc = num_cores  # Theoretical maximum if perfect scaling\n",
    "\n",
    "# Parallel efficiency calculation\n",
    "parallel_efficiency = (combined_ipc / theoretical_max_ipc) * 100\n",
    "scaling_factor = combined_ipc\n",
    "\n",
    "print(f\"PARALLEL COMPUTING METRICS:\")\n",
    "print(f\"   Number of Cores/Threads: {num_cores}\")\n",
    "print(f\"   Combined IPC: {combined_ipc:.3f}\")\n",
    "print(f\"   Theoretical Maximum IPC: {theoretical_max_ipc:.1f}\")\n",
    "print(f\"   Parallel Efficiency: {parallel_efficiency:.1f}%\")\n",
    "print(f\"   Scaling Factor: {scaling_factor:.2f}x\")\n",
    "\n",
    "# Performance rating\n",
    "if parallel_efficiency > 90:\n",
    "    efficiency_rating = \"Excellent\"\n",
    "    efficiency_desc = \"Outstanding parallel scaling\"\n",
    "elif parallel_efficiency > 80:\n",
    "    efficiency_rating = \"Very Good\"\n",
    "    efficiency_desc = \"Strong parallel performance\"\n",
    "elif parallel_efficiency > 60:\n",
    "    efficiency_rating = \"Good\"\n",
    "    efficiency_desc = \"Reasonable parallel scaling with room for improvement\"\n",
    "else:\n",
    "    efficiency_rating = \"Needs Improvement\"\n",
    "    efficiency_desc = \"Poor parallel scaling - investigate bottlenecks\"\n",
    "\n",
    "print(f\"\\nEFFICIENCY ASSESSMENT:\")\n",
    "print(f\"   Rating: {efficiency_rating}\")\n",
    "print(f\"   Assessment: {efficiency_desc}\")\n",
    "\n",
    "# Load balancing analysis\n",
    "print(f\"\\nLOAD BALANCING ANALYSIS:\")\n",
    "if num_cores == 2:\n",
    "    instructions_per_thread = total_instructions // num_cores\n",
    "    print(f\"   Average Instructions per Thread: {instructions_per_thread:,}\")\n",
    "    \n",
    "    # Estimate load balance (perfect would be equal distribution)\n",
    "    load_balance_quality = \"Perfect\" if parallel_efficiency > 85 else \"Good\" if parallel_efficiency > 70 else \"Unbalanced\"\n",
    "    print(f\"   Load Balance Quality: {load_balance_quality}\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "multicore_data = {\n",
    "    \"Metric\": [\n",
    "        \"Number of Cores\",\n",
    "        \"Total Cycles\",\n",
    "        \"Total Instructions\",\n",
    "        \"Combined IPC\",\n",
    "        \"Parallel Efficiency (%)\",\n",
    "        \"Scaling Factor\",\n",
    "        \"L1 I-Cache Hit Rate (%)\",\n",
    "        \"L1 D-Cache Hit Rate (%)\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        f\"{num_cores}\",\n",
    "        f\"{total_cycles:,}\",\n",
    "        f\"{total_instructions:,}\",\n",
    "        f\"{combined_ipc:.3f}\",\n",
    "        f\"{parallel_efficiency:.1f}\",\n",
    "        f\"{scaling_factor:.2f}x\",\n",
    "        f\"{l1_icache_hit_rate:.2f}\",\n",
    "        f\"{l1_dcache_hit_rate:.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "multicore_df = pd.DataFrame(multicore_data)\n",
    "display(multicore_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e50b2",
   "metadata": {},
   "source": [
    "## Advanced Multicore Analysis\n",
    "\n",
    "Let's dive deeper into multicore-specific performance characteristics and optimization opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e10bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Multicore Performance Insights\n",
    "print(\"ADVANCED MULTICORE OPTIMIZATION INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"THREAD EFFICIENCY ANALYSIS:\")\n",
    "\n",
    "# Thread efficiency insights\n",
    "if parallel_efficiency > 90:\n",
    "    print(\"   Outstanding thread coordination and minimal overhead\")\n",
    "    print(\"   Recommendation: Consider scaling to more cores for increased throughput\")\n",
    "elif parallel_efficiency > 80:\n",
    "    print(\"   Good parallel scaling with acceptable overhead\")\n",
    "    print(\"   Recommendation: Minor optimizations could improve efficiency further\")\n",
    "else:\n",
    "    print(\"   Significant parallel overhead detected\")\n",
    "    print(\"   Recommendation: Investigate synchronization, memory contention, or load imbalance\")\n",
    "\n",
    "print(f\"\\nCACHE SHARING ANALYSIS:\")\n",
    "\n",
    "# Cache performance under parallel load\n",
    "if l1_icache_hit_rate > 99 and l1_dcache_hit_rate > 99:\n",
    "    print(\"   Excellent cache performance maintained under parallel load\")\n",
    "    print(\"   Recommendation: Memory access patterns are cache-friendly across threads\")\n",
    "elif l1_icache_hit_rate > 95 and l1_dcache_hit_rate > 95:\n",
    "    print(\"   Good cache utilization with minimal thread interference\")\n",
    "    print(\"   Recommendation: Consider data partitioning optimizations\")\n",
    "else:\n",
    "    print(\"   Cache performance degraded under parallel load\")\n",
    "    print(\"   Recommendation: Optimize data access patterns to reduce cache conflicts\")\n",
    "\n",
    "print(f\"\\nSCALING RECOMMENDATIONS:\")\n",
    "\n",
    "if parallel_efficiency > 85:\n",
    "    print(\"   Ready for aggressive scaling to 4+ cores\")\n",
    "    print(\"   Next experiment: Try I8500_(4_threads) configuration\")\n",
    "    print(\"   Expected outcome: Strong performance gains with more cores\")\n",
    "elif parallel_efficiency > 70:\n",
    "    print(\"   Moderate scaling potential to 4 cores\")\n",
    "    print(\"   Recommendation: Optimize current 2-core performance before scaling up\")\n",
    "    print(\"   Focus areas: Load balancing and cache optimization\")\n",
    "else:\n",
    "    print(\"   Address parallel bottlenecks before scaling up\")\n",
    "    print(\"   Investigation needed: Thread synchronization and memory access patterns\")\n",
    "    print(\"   Consider: Workload partitioning strategies\")\n",
    "\n",
    "print(f\"\\nMULTICORE OPTIMIZATION STRATEGIES:\")\n",
    "print(\"   • Thread Affinity: Pin threads to specific cores\")\n",
    "print(\"   • Data Locality: Minimize cross-thread memory sharing\")\n",
    "print(\"   • Load Balancing: Ensure equal work distribution\")\n",
    "print(\"   • Cache Optimization: Reduce false sharing between threads\")\n",
    "print(\"   • NUMA Awareness: Consider memory topology for larger systems\")\n",
    "\n",
    "print(f\"\\nComplete multicore analysis saved to: {results_dir}/{experiment_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e66551",
   "metadata": {},
   "source": [
    "## Multicore Analysis Summary\n",
    "\n",
    "**Excellent work!** You've successfully completed a comprehensive multicore performance analysis using Atlas Explorer 3.0.\n",
    "\n",
    "### What You Accomplished:\n",
    "- Configured Atlas Explorer 3.0 for multicore analysis\n",
    "- Ran parallel workloads across multiple threads\n",
    "- Analyzed parallel efficiency and scaling characteristics\n",
    "- Evaluated thread load balancing and cache sharing\n",
    "- Generated advanced multicore optimization insights\n",
    "\n",
    "### Advanced Experiments to Try:\n",
    "1. **Scale Up**: Try `I8500_(4_threads)` for quad-core analysis\n",
    "2. **Compare Configurations**: Run same workloads on different core counts\n",
    "3. **Optimize Workloads**: Test with `-O3` optimized ELF files\n",
    "4. **Custom Workloads**: Analyze your own parallel applications\n",
    "5. **Scaling Studies**: Create performance scaling curves\n",
    "\n",
    "### Research Opportunities:\n",
    "- **Parallel Overhead Analysis**: Quantify coordination costs\n",
    "- **Cache Coherency Studies**: Analyze inter-thread cache behavior\n",
    "- **NUMA Performance**: Study memory topology effects\n",
    "- **Workload Characterization**: Profile different parallel patterns\n",
    "\n",
    "### Continue Learning:\n",
    "- [Command-line automation](../examples/)\n",
    "- [Single-core analysis](ae_singlecore_notebook.ipynb)\n",
    "- [Full documentation](../README.md)\n",
    "- [Advanced configuration options](../README.md#configuration-guide)\n",
    "\n",
    "**Congratulations on mastering multicore performance analysis with Atlas Explorer 3.0!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23245852",
   "metadata": {},
   "source": [
    "# 🚀 ATLAS Explorer 3.0 - Multicore Performance Analysis\n",
    "\n",
    "This notebook demonstrates **multicore CPU performance analysis** using the Atlas Explorer 3.0 modular architecture.\n",
    "\n",
    "## 📚 What You'll Master\n",
    "- 🖥️ Thread load balancing and parallel efficiency\n",
    "- ⚡ Resource contention analysis and optimization\n",
    "- 📊 Scaling studies across different core counts  \n",
    "- 🔄 Cache sharing and memory system behavior\n",
    "- 🚀 Advanced multicore optimization techniques\n",
    "\n",
    "## 🎯 Prerequisites\n",
    "- Atlas Explorer credentials configured (`atlasexplorer configure`)\n",
    "- Package installed with notebook dependencies (`uv pip install -e '.[notebooks]'`)\n",
    "- Familiarity with single-core analysis (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📚 Import Required Libraries for Multicore Analysis\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Atlas Explorer 3.0 modular imports\n",
    "from atlasexplorer.core.client import AtlasExplorer\n",
    "from atlasexplorer.core.experiment import Experiment\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(\"🚀 Atlas Explorer 3.0 - Ready for multicore analysis\")\n",
    "print(\"🖥️ Parallel computing performance insights coming up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc6e66b",
   "metadata": {},
   "source": [
    "## 🔧 Configuration Check\n",
    "\n",
    "Let's verify that your Atlas Explorer credentials are properly configured for multicore experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba17f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Check Atlas Explorer Configuration for Multicore\n",
    "print(\"🔧 Checking Atlas Explorer Configuration for Multicore...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Initialize Atlas Explorer client\n",
    "    ae = AtlasExplorer(channel=\"development\", verbose=True)\n",
    "    \n",
    "    print(\"✅ Configuration Status: READY FOR MULTICORE\")\n",
    "    print(f\"🌐 Gateway: {ae.config.gateway}\")\n",
    "    print(f\"📡 Channel: {ae.config.channel}\")\n",
    "    print(f\"🌍 Region: {ae.config.region}\")\n",
    "    print(f\"🔑 API Key: {ae.config.apikey[:8]}...\")\n",
    "    print(\"🖥️ Ready for parallel computing analysis!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"❌ Configuration Error:\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\n💡 To fix this, run: atlasexplorer configure\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c70980",
   "metadata": {},
   "source": [
    "## 📁 Experiment History\n",
    "\n",
    "Let's check your previous experiments to see any multicore analysis history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc951d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📁 Display Previous Multicore Experiments\n",
    "print(\"📁 Previous Atlas Explorer Experiments:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "experiment_dir = Path(\"myexperiments\")\n",
    "experiments = []\n",
    "\n",
    "if experiment_dir.exists():\n",
    "    for exp_path in experiment_dir.iterdir():\n",
    "        if exp_path.is_dir():\n",
    "            config_file = exp_path / \"config.json\"\n",
    "            if config_file.exists():\n",
    "                try:\n",
    "                    with open(config_file) as f:\n",
    "                        config = json.load(f)\n",
    "                    \n",
    "                    mod_time = datetime.fromtimestamp(exp_path.stat().st_mtime)\n",
    "                    core_config = config.get(\"core\", \"unknown\")\n",
    "                    \n",
    "                    experiments.append({\n",
    "                        \"Experiment\": exp_path.name,\n",
    "                        \"Channel\": config.get(\"channel\", \"unknown\"),\n",
    "                        \"Core\": core_config,\n",
    "                        \"Type\": \"Multicore\" if \"thread\" in core_config and not \"1_thread\" in core_config else \"Single-core\",\n",
    "                        \"Modified\": mod_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    })\n",
    "                except (json.JSONDecodeError, KeyError):\n",
    "                    continue\n",
    "\n",
    "if experiments:\n",
    "    df = pd.DataFrame(experiments).sort_values(\"Modified\", ascending=False)\n",
    "    display(df)\n",
    "    \n",
    "    multicore_count = sum(1 for exp in experiments if \"Multicore\" in exp[\"Type\"])\n",
    "    print(f\"\\n📊 Found {len(experiments)} total experiments ({multicore_count} multicore)\")\n",
    "else:\n",
    "    print(\"No previous experiments found. This will be your first multicore experiment!\")\n",
    "    print(\"🆕 Creating 'myexperiments' directory for results...\")\n",
    "    experiment_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d012bbee",
   "metadata": {},
   "source": [
    "## 🖥️ Multicore Experiment Setup\n",
    "\n",
    "Now let's set up a multicore experiment using multiple workloads to analyze parallel performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7831f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🖥️ Multicore Experiment Configuration\n",
    "print(\"🖥️ Setting up Multicore Performance Experiment\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Experiment parameters\n",
    "elf_files = [\n",
    "    \"resources/mandelbrot_rv64_O0.elf\",\n",
    "    \"resources/memcpy_rv64.elf\"\n",
    "]\n",
    "core_config = \"I8500_(2_threads)\"  # 2-core configuration\n",
    "experiment_name = \"multicore_parallel_analysis\"\n",
    "results_dir = \"myexperiments\"\n",
    "\n",
    "print(f\"📁 ELF Files:\")\n",
    "for i, elf_file in enumerate(elf_files, 1):\n",
    "    print(f\"   {i}. {elf_file}\")\n",
    "print(f\"🖥️ Core Configuration: {core_config}\")\n",
    "print(f\"📊 Experiment Name: {experiment_name}\")\n",
    "print(f\"💾 Results Directory: {results_dir}\")\n",
    "\n",
    "# Verify all ELF files exist\n",
    "missing_files = []\n",
    "for elf_file in elf_files:\n",
    "    if not os.path.exists(elf_file):\n",
    "        missing_files.append(elf_file)\n",
    "    else:\n",
    "        print(f\"✅ Verified: {elf_file}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"❌ Error: Missing ELF files: {missing_files}\")\n",
    "    print(\"💡 Make sure you're running from the repository root directory\")\n",
    "    raise FileNotFoundError(f\"ELF files not found: {missing_files}\")\n",
    "    \n",
    "print(\"\\n🚀 Ready to launch multicore experiment!\")\n",
    "print(f\"🧵 This will analyze parallel execution across {core_config.split('_')[1].replace('(', '').replace(')', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c26502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Launch Multicore Experiment\n",
    "print(\"🚀 Launching Multicore Performance Analysis...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Create experiment\n",
    "    experiment = Experiment(experiment_name, ae)\n",
    "    \n",
    "    # Configure experiment with multiple workloads\n",
    "    for elf_file in elf_files:\n",
    "        experiment.addWorkload(elf_file)\n",
    "    \n",
    "    experiment.setCore(core_config)\n",
    "    experiment.setResultsDir(results_dir)\n",
    "    \n",
    "    print(f\"📋 Multicore experiment configured:\")\n",
    "    print(f\"   • Name: {experiment_name}\")\n",
    "    print(f\"   • Workloads: {len(elf_files)} parallel tasks\")\n",
    "    for i, elf_file in enumerate(elf_files, 1):\n",
    "        print(f\"     {i}. {os.path.basename(elf_file)}\")\n",
    "    print(f\"   • Core: {core_config}\")\n",
    "    print(f\"   • Channel: {ae.config.channel}\")\n",
    "    \n",
    "    # Run experiment\n",
    "    print(\"\\n⏳ Running multicore experiment... (this may take 2-5 minutes)\")\n",
    "    print(\"🧵 Analyzing parallel execution, thread load balancing, and resource sharing...\")\n",
    "    experiment.run()\n",
    "    \n",
    "    print(\"\\n✅ Multicore experiment completed successfully!\")\n",
    "    print(f\"📁 Results saved to: {results_dir}/{experiment_name}/\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Experiment failed: {e}\")\n",
    "    print(\"💡 Check your network connection and credentials\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003994e7",
   "metadata": {},
   "source": [
    "## 📊 Multicore Performance Results\n",
    "\n",
    "Now let's analyze the parallel performance results and thread efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137557a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Extract and Display Multicore Performance Metrics\n",
    "print(\"📊 MULTICORE PERFORMANCE ANALYSIS RESULTS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Get experiment summary\n",
    "summary = experiment.getSummary()\n",
    "\n",
    "# Overall performance metrics\n",
    "total_cycles = summary.getTotalCycles()\n",
    "total_instructions = summary.getTotalInstructions()\n",
    "combined_ipc = summary.getIPC()\n",
    "l1_icache_hit_rate = summary.getL1InstructionCacheHitRate()\n",
    "l1_dcache_hit_rate = summary.getL1DataCacheHitRate()\n",
    "\n",
    "print(f\"🎯 OVERALL MULTICORE RESULTS:\")\n",
    "print(f\"   Total Cycles: {total_cycles:,}\")\n",
    "print(f\"   Instructions Executed: {total_instructions:,}\")\n",
    "print(f\"   Combined IPC: {combined_ipc:.3f}\")\n",
    "print(f\"\\n💾 SHARED CACHE PERFORMANCE:\")\n",
    "print(f\"   L1 Instruction Cache Hit Rate: {l1_icache_hit_rate:.2f}%\")\n",
    "print(f\"   L1 Data Cache Hit Rate: {l1_dcache_hit_rate:.2f}%\")\n",
    "\n",
    "# Try to get per-thread metrics if available\n",
    "print(f\"\\n🧵 THREAD-LEVEL ANALYSIS:\")\n",
    "try:\n",
    "    # This may vary depending on the exact API\n",
    "    thread_metrics = summary.getThreadMetrics() if hasattr(summary, 'getThreadMetrics') else None\n",
    "    if thread_metrics:\n",
    "        for i, thread in enumerate(thread_metrics):\n",
    "            print(f\"   Thread {i}: {thread['instructions']:,} instructions, IPC: {thread['ipc']:.3f}\")\n",
    "    else:\n",
    "        # Estimate thread distribution\n",
    "        estimated_instructions_per_thread = total_instructions // len(elf_files)\n",
    "        estimated_ipc_per_thread = combined_ipc / len(elf_files)\n",
    "        \n",
    "        for i in range(len(elf_files)):\n",
    "            print(f\"   Thread {i} (estimated): ~{estimated_instructions_per_thread:,} instructions, IPC: ~{estimated_ipc_per_thread:.3f}\")\n",
    "        print(f\"   📝 Note: Per-thread metrics estimated from combined results\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ⚠️ Individual thread metrics not available: {e}\")\n",
    "    print(f\"   📊 Combined metrics shown above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 Parallel Efficiency Analysis\n",
    "print(\"📈 PARALLEL EFFICIENCY & SCALING ANALYSIS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Calculate parallel efficiency metrics\n",
    "num_cores = len(elf_files)\n",
    "theoretical_max_ipc = num_cores  # Theoretical maximum if perfect scaling\n",
    "\n",
    "# Parallel efficiency calculation\n",
    "parallel_efficiency = (combined_ipc / theoretical_max_ipc) * 100\n",
    "scaling_factor = combined_ipc\n",
    "\n",
    "print(f\"🖥️ PARALLEL COMPUTING METRICS:\")\n",
    "print(f\"   Number of Cores/Threads: {num_cores}\")\n",
    "print(f\"   Combined IPC: {combined_ipc:.3f}\")\n",
    "print(f\"   Theoretical Maximum IPC: {theoretical_max_ipc:.1f}\")\n",
    "print(f\"   Parallel Efficiency: {parallel_efficiency:.1f}%\")\n",
    "print(f\"   Scaling Factor: {scaling_factor:.2f}x\")\n",
    "\n",
    "# Performance rating\n",
    "if parallel_efficiency > 90:\n",
    "    efficiency_rating = \"🌟 Excellent\"\n",
    "    efficiency_desc = \"Outstanding parallel scaling\"\n",
    "elif parallel_efficiency > 80:\n",
    "    efficiency_rating = \"✅ Very Good\"\n",
    "    efficiency_desc = \"Strong parallel performance\"\n",
    "elif parallel_efficiency > 60:\n",
    "    efficiency_rating = \"⚠️ Good\"\n",
    "    efficiency_desc = \"Reasonable parallel scaling with room for improvement\"\n",
    "else:\n",
    "    efficiency_rating = \"❌ Needs Improvement\"\n",
    "    efficiency_desc = \"Poor parallel scaling - investigate bottlenecks\"\n",
    "\n",
    "print(f\"\\n🎯 EFFICIENCY ASSESSMENT:\")\n",
    "print(f\"   Rating: {efficiency_rating}\")\n",
    "print(f\"   Assessment: {efficiency_desc}\")\n",
    "\n",
    "# Load balancing analysis\n",
    "print(f\"\\n⚖️ LOAD BALANCING ANALYSIS:\")\n",
    "if num_cores == 2:\n",
    "    instructions_per_thread = total_instructions // num_cores\n",
    "    print(f\"   Average Instructions per Thread: {instructions_per_thread:,}\")\n",
    "    \n",
    "    # Estimate load balance (perfect would be equal distribution)\n",
    "    load_balance_quality = \"🏆 Perfect\" if parallel_efficiency > 85 else \"✅ Good\" if parallel_efficiency > 70 else \"⚠️ Unbalanced\"\n",
    "    print(f\"   Load Balance Quality: {load_balance_quality}\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "multicore_data = {\n",
    "    \"Metric\": [\n",
    "        \"🖥️ Number of Cores\",\n",
    "        \"🎯 Total Cycles\",\n",
    "        \"📊 Total Instructions\",\n",
    "        \"⚡ Combined IPC\",\n",
    "        \"📈 Parallel Efficiency (%)\",\n",
    "        \"🚀 Scaling Factor\",\n",
    "        \"💾 L1 I-Cache Hit Rate (%)\",\n",
    "        \"💾 L1 D-Cache Hit Rate (%)\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        f\"{num_cores}\",\n",
    "        f\"{total_cycles:,}\",\n",
    "        f\"{total_instructions:,}\",\n",
    "        f\"{combined_ipc:.3f}\",\n",
    "        f\"{parallel_efficiency:.1f}\",\n",
    "        f\"{scaling_factor:.2f}x\",\n",
    "        f\"{l1_icache_hit_rate:.2f}\",\n",
    "        f\"{l1_dcache_hit_rate:.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "multicore_df = pd.DataFrame(multicore_data)\n",
    "display(multicore_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e72361",
   "metadata": {},
   "source": [
    "## 🔍 Advanced Multicore Analysis\n",
    "\n",
    "Let's dive deeper into multicore-specific performance characteristics and optimization opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Advanced Multicore Performance Insights\n",
    "print(\"🔍 ADVANCED MULTICORE OPTIMIZATION INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"🧵 THREAD EFFICIENCY ANALYSIS:\")\n",
    "\n",
    "# Thread efficiency insights\n",
    "if parallel_efficiency > 90:\n",
    "    print(\"   🌟 Outstanding thread coordination and minimal overhead\")\n",
    "    print(\"   💡 Consider scaling to more cores for increased throughput\")\n",
    "elif parallel_efficiency > 80:\n",
    "    print(\"   ✅ Good parallel scaling with acceptable overhead\")\n",
    "    print(\"   💡 Minor optimizations could improve efficiency further\")\n",
    "else:\n",
    "    print(\"   ⚠️ Significant parallel overhead detected\")\n",
    "    print(\"   💡 Investigate synchronization, memory contention, or load imbalance\")\n",
    "\n",
    "print(f\"\\n💾 CACHE SHARING ANALYSIS:\")\n",
    "\n",
    "# Cache performance under parallel load\n",
    "if l1_icache_hit_rate > 99 and l1_dcache_hit_rate > 99:\n",
    "    print(\"   🌟 Excellent cache performance maintained under parallel load\")\n",
    "    print(\"   💡 Memory access patterns are cache-friendly across threads\")\n",
    "elif l1_icache_hit_rate > 95 and l1_dcache_hit_rate > 95:\n",
    "    print(\"   ✅ Good cache utilization with minimal thread interference\")\n",
    "    print(\"   💡 Consider data partitioning optimizations\")\n",
    "else:\n",
    "    print(\"   ⚠️ Cache performance degraded under parallel load\")\n",
    "    print(\"   💡 Optimize data access patterns to reduce cache conflicts\")\n",
    "\n",
    "print(f\"\\n🚀 SCALING RECOMMENDATIONS:\")\n",
    "\n",
    "if parallel_efficiency > 85:\n",
    "    print(\"   🎯 Ready for aggressive scaling to 4+ cores\")\n",
    "    print(\"   💡 Try I8500_(4_threads) configuration for next experiment\")\n",
    "    print(\"   📈 Expect strong performance gains with more cores\")\n",
    "elif parallel_efficiency > 70:\n",
    "    print(\"   ⚡ Moderate scaling potential to 4 cores\")\n",
    "    print(\"   💡 Optimize current 2-core performance before scaling up\")\n",
    "    print(\"   🔧 Focus on load balancing and cache optimization\")\n",
    "else:\n",
    "    print(\"   ⚠️ Address parallel bottlenecks before scaling up\")\n",
    "    print(\"   💡 Investigate thread synchronization and memory access patterns\")\n",
    "    print(\"   🔧 Consider workload partitioning strategies\")\n",
    "\n",
    "print(f\"\\n🏆 MULTICORE OPTIMIZATION STRATEGIES:\")\n",
    "print(\"   • 🧵 Thread Affinity: Pin threads to specific cores\")\n",
    "print(\"   • 💾 Data Locality: Minimize cross-thread memory sharing\")\n",
    "print(\"   • ⚖️ Load Balancing: Ensure equal work distribution\")\n",
    "print(\"   • 🔄 Cache Optimization: Reduce false sharing between threads\")\n",
    "print(\"   • 📊 NUMA Awareness: Consider memory topology for larger systems\")\n",
    "\n",
    "print(f\"\\n📁 Complete multicore analysis saved to: {results_dir}/{experiment_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff528d",
   "metadata": {},
   "source": [
    "## 🏁 Multicore Analysis Summary\n",
    "\n",
    "**Excellent work!** You've successfully completed a comprehensive multicore performance analysis using Atlas Explorer 3.0.\n",
    "\n",
    "### 📋 What You Accomplished:\n",
    "- ✅ Configured Atlas Explorer 3.0 for multicore analysis\n",
    "- ✅ Ran parallel workloads across multiple threads\n",
    "- ✅ Analyzed parallel efficiency and scaling characteristics\n",
    "- ✅ Evaluated thread load balancing and cache sharing\n",
    "- ✅ Generated advanced multicore optimization insights\n",
    "\n",
    "### 🚀 Advanced Experiments to Try:\n",
    "1. **Scale Up**: Try `I8500_(4_threads)` for quad-core analysis\n",
    "2. **Compare Configurations**: Run same workloads on different core counts\n",
    "3. **Optimize Workloads**: Test with `-O3` optimized ELF files\n",
    "4. **Custom Workloads**: Analyze your own parallel applications\n",
    "5. **Scaling Studies**: Create performance scaling curves\n",
    "\n",
    "### 🔬 Research Opportunities:\n",
    "- **Parallel Overhead Analysis**: Quantify coordination costs\n",
    "- **Cache Coherency Studies**: Analyze inter-thread cache behavior\n",
    "- **NUMA Performance**: Study memory topology effects\n",
    "- **Workload Characterization**: Profile different parallel patterns\n",
    "\n",
    "### 📚 Continue Learning:\n",
    "- 📖 [Command-line automation](../examples/)\n",
    "- 🔬 [Single-core analysis](ae_singlecore_notebook.ipynb)\n",
    "- 📊 [Full documentation](../README.md)\n",
    "- 🏗️ [Advanced configuration options](../README.md#configuration-guide)\n",
    "\n",
    "**🎉 Congratulations on mastering multicore performance analysis with Atlas Explorer 3.0!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
