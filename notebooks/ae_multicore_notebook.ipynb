{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e539b14",
   "metadata": {},
   "source": [
    "# Atlas Explorer 3.0 - Multicore Performance Analysis\n",
    "\n",
    "This notebook demonstrates **multicore CPU performance analysis** using the Atlas Explorer 3.0 modular architecture.\n",
    "\n",
    "## Learning Objectives\n",
    "- Configure Atlas Explorer for multicore analysis\n",
    "- Execute parallel workloads across multiple threads\n",
    "- Analyze thread load balancing and scaling efficiency\n",
    "- Understand resource contention and cache sharing\n",
    "- Generate advanced multicore optimization insights\n",
    "\n",
    "## Prerequisites\n",
    "- Atlas Explorer credentials configured (`atlasexplorer configure`)\n",
    "- Package installed with notebook dependencies (`uv pip install -e '.[notebooks]'`)\n",
    "- Familiarity with single-core analysis (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries for Multicore Analysis\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Atlas Explorer 3.0 modular imports\n",
    "from atlasexplorer.core.client import AtlasExplorer\n",
    "from atlasexplorer.core.experiment import Experiment\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Atlas Explorer 3.0 - Ready for multicore analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b319904",
   "metadata": {},
   "source": [
    "## Configuration Check\n",
    "\n",
    "Let's verify that your Atlas Explorer credentials are properly configured for multicore experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e8ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Atlas Explorer Configuration for Multicore\n",
    "print(\"Checking Atlas Explorer Configuration for Multicore...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Initialize Atlas Explorer client\n",
    "    ae = AtlasExplorer(channel=\"development\", verbose=True)\n",
    "    \n",
    "    print(\"Configuration Status: READY FOR MULTICORE\")\n",
    "    print(f\"Gateway: {ae.config.gateway}\")\n",
    "    print(f\"Channel: {ae.config.channel}\")\n",
    "    print(f\"Region: {ae.config.region}\")\n",
    "    print(f\"API Key: {ae.config.apikey[:8]}...\")\n",
    "    print(\"Ready for parallel computing analysis!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Configuration Error:\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nTo fix this, run: atlasexplorer configure\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b513e7a",
   "metadata": {},
   "source": [
    "## Experiment History\n",
    "\n",
    "Let's check your previous experiments to see any multicore analysis history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744451f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Previous Multicore Experiments\n",
    "print(\"Previous Atlas Explorer Experiments:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "experiment_dir = Path(\"myexperiments\")\n",
    "experiments = []\n",
    "\n",
    "if experiment_dir.exists():\n",
    "    for exp_path in experiment_dir.iterdir():\n",
    "        if exp_path.is_dir():\n",
    "            config_file = exp_path / \"config.json\"\n",
    "            if config_file.exists():\n",
    "                try:\n",
    "                    with open(config_file) as f:\n",
    "                        config = json.load(f)\n",
    "                    \n",
    "                    mod_time = datetime.fromtimestamp(exp_path.stat().st_mtime)\n",
    "                    core_config = config.get(\"core\", \"unknown\")\n",
    "                    \n",
    "                    experiments.append({\n",
    "                        \"Experiment\": exp_path.name,\n",
    "                        \"Channel\": config.get(\"channel\", \"unknown\"),\n",
    "                        \"Core\": core_config,\n",
    "                        \"Type\": \"Multicore\" if \"thread\" in core_config and not \"1_thread\" in core_config else \"Single-core\",\n",
    "                        \"Modified\": mod_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    })\n",
    "                except (json.JSONDecodeError, KeyError):\n",
    "                    continue\n",
    "\n",
    "if experiments:\n",
    "    df = pd.DataFrame(experiments).sort_values(\"Modified\", ascending=False)\n",
    "    display(df)\n",
    "    \n",
    "    multicore_count = sum(1 for exp in experiments if \"Multicore\" in exp[\"Type\"])\n",
    "    print(f\"\\nFound {len(experiments)} total experiments ({multicore_count} multicore)\")\n",
    "else:\n",
    "    print(\"No previous experiments found. This will be your first multicore experiment!\")\n",
    "    print(\"Creating 'myexperiments' directory for results...\")\n",
    "    experiment_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be22f3d",
   "metadata": {},
   "source": [
    "## Multicore Experiment Setup\n",
    "\n",
    "Now let's set up a multicore experiment using multiple workloads to analyze parallel performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb518e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multicore Experiment Configuration\n",
    "print(\"Setting up Multicore Performance Experiment\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Experiment parameters\n",
    "elf_files = [\n",
    "    \"resources/mandelbrot_rv64_O0.elf\",\n",
    "    \"resources/memcpy_rv64.elf\"\n",
    "]\n",
    "core_config = \"I8500_(2_threads)\"  # 2-core configuration\n",
    "experiment_name = \"multicore_parallel_analysis\"\n",
    "results_dir = \"myexperiments\"\n",
    "\n",
    "print(f\"ELF Files:\")\n",
    "for i, elf_file in enumerate(elf_files, 1):\n",
    "    print(f\"   {i}. {elf_file}\")\n",
    "print(f\"Core Configuration: {core_config}\")\n",
    "print(f\"Experiment Name: {experiment_name}\")\n",
    "print(f\"Results Directory: {results_dir}\")\n",
    "\n",
    "# Verify all ELF files exist\n",
    "missing_files = []\n",
    "for elf_file in elf_files:\n",
    "    if not os.path.exists(elf_file):\n",
    "        missing_files.append(elf_file)\n",
    "    else:\n",
    "        print(f\"Verified: {elf_file}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"Error: Missing ELF files: {missing_files}\")\n",
    "    print(\"Make sure you're running from the repository root directory\")\n",
    "    raise FileNotFoundError(f\"ELF files not found: {missing_files}\")\n",
    "    \n",
    "print(\"\\nReady to launch multicore experiment!\")\n",
    "print(f\"This will analyze parallel execution across {core_config.split('_')[1].replace('(', '').replace(')', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c9aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch Multicore Experiment\n",
    "print(\"Launching Multicore Performance Analysis...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Create experiment\n",
    "    experiment = Experiment(experiment_name, ae)\n",
    "    \n",
    "    # Configure experiment with multiple workloads\n",
    "    for elf_file in elf_files:\n",
    "        experiment.addWorkload(elf_file)\n",
    "    \n",
    "    experiment.setCore(core_config)\n",
    "    experiment.setResultsDir(results_dir)\n",
    "    \n",
    "    print(f\"Multicore experiment configured:\")\n",
    "    print(f\"   Name: {experiment_name}\")\n",
    "    print(f\"   Workloads: {len(elf_files)} parallel tasks\")\n",
    "    for i, elf_file in enumerate(elf_files, 1):\n",
    "        print(f\"     {i}. {os.path.basename(elf_file)}\")\n",
    "    print(f\"   Core: {core_config}\")\n",
    "    print(f\"   Channel: {ae.config.channel}\")\n",
    "    \n",
    "    # Run experiment\n",
    "    print(\"\\nRunning multicore experiment... (this may take 2-5 minutes)\")\n",
    "    print(\"Analyzing parallel execution, thread load balancing, and resource sharing...\")\n",
    "    experiment.run()\n",
    "    \n",
    "    print(\"\\nMulticore experiment completed successfully!\")\n",
    "    print(f\"Results saved to: {results_dir}/{experiment_name}/\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Experiment failed: {e}\")\n",
    "    print(\"Check your network connection and credentials\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067da4a",
   "metadata": {},
   "source": [
    "## Multicore Performance Results\n",
    "\n",
    "Now let's analyze the parallel performance results and thread efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and Display Multicore Performance Metrics\n",
    "print(\"MULTICORE PERFORMANCE ANALYSIS RESULTS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Get experiment summary\n",
    "summary = experiment.getSummary()\n",
    "\n",
    "# Overall performance metrics\n",
    "total_cycles = summary.getTotalCycles()\n",
    "total_instructions = summary.getTotalInstructions()\n",
    "combined_ipc = summary.getIPC()\n",
    "l1_icache_hit_rate = summary.getL1InstructionCacheHitRate()\n",
    "l1_dcache_hit_rate = summary.getL1DataCacheHitRate()\n",
    "\n",
    "print(f\"OVERALL MULTICORE RESULTS:\")\n",
    "print(f\"   Total Cycles: {total_cycles:,}\")\n",
    "print(f\"   Instructions Executed: {total_instructions:,}\")\n",
    "print(f\"   Combined IPC: {combined_ipc:.3f}\")\n",
    "print(f\"\\nSHARED CACHE PERFORMANCE:\")\n",
    "print(f\"   L1 Instruction Cache Hit Rate: {l1_icache_hit_rate:.2f}%\")\n",
    "print(f\"   L1 Data Cache Hit Rate: {l1_dcache_hit_rate:.2f}%\")\n",
    "\n",
    "# Try to get per-thread metrics if available\n",
    "print(f\"\\nTHREAD-LEVEL ANALYSIS:\")\n",
    "try:\n",
    "    # This may vary depending on the exact API\n",
    "    thread_metrics = summary.getThreadMetrics() if hasattr(summary, 'getThreadMetrics') else None\n",
    "    if thread_metrics:\n",
    "        for i, thread in enumerate(thread_metrics):\n",
    "            print(f\"   Thread {i}: {thread['instructions']:,} instructions, IPC: {thread['ipc']:.3f}\")\n",
    "    else:\n",
    "        # Estimate thread distribution\n",
    "        estimated_instructions_per_thread = total_instructions // len(elf_files)\n",
    "        estimated_ipc_per_thread = combined_ipc / len(elf_files)\n",
    "        \n",
    "        for i in range(len(elf_files)):\n",
    "            print(f\"   Thread {i} (estimated): ~{estimated_instructions_per_thread:,} instructions, IPC: ~{estimated_ipc_per_thread:.3f}\")\n",
    "        print(f\"   Note: Per-thread metrics estimated from combined results\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   Warning: Individual thread metrics not available: {e}\")\n",
    "    print(f\"   Combined metrics shown above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5caab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel Efficiency Analysis\n",
    "print(\"PARALLEL EFFICIENCY & SCALING ANALYSIS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Calculate parallel efficiency metrics\n",
    "num_cores = len(elf_files)\n",
    "theoretical_max_ipc = num_cores  # Theoretical maximum if perfect scaling\n",
    "\n",
    "# Parallel efficiency calculation\n",
    "parallel_efficiency = (combined_ipc / theoretical_max_ipc) * 100\n",
    "scaling_factor = combined_ipc\n",
    "\n",
    "print(f\"PARALLEL COMPUTING METRICS:\")\n",
    "print(f\"   Number of Cores/Threads: {num_cores}\")\n",
    "print(f\"   Combined IPC: {combined_ipc:.3f}\")\n",
    "print(f\"   Theoretical Maximum IPC: {theoretical_max_ipc:.1f}\")\n",
    "print(f\"   Parallel Efficiency: {parallel_efficiency:.1f}%\")\n",
    "print(f\"   Scaling Factor: {scaling_factor:.2f}x\")\n",
    "\n",
    "# Performance rating\n",
    "if parallel_efficiency > 90:\n",
    "    efficiency_rating = \"Excellent\"\n",
    "    efficiency_desc = \"Outstanding parallel scaling\"\n",
    "elif parallel_efficiency > 80:\n",
    "    efficiency_rating = \"Very Good\"\n",
    "    efficiency_desc = \"Strong parallel performance\"\n",
    "elif parallel_efficiency > 60:\n",
    "    efficiency_rating = \"Good\"\n",
    "    efficiency_desc = \"Reasonable parallel scaling with room for improvement\"\n",
    "else:\n",
    "    efficiency_rating = \"Needs Improvement\"\n",
    "    efficiency_desc = \"Poor parallel scaling - investigate bottlenecks\"\n",
    "\n",
    "print(f\"\\nEFFICIENCY ASSESSMENT:\")\n",
    "print(f\"   Rating: {efficiency_rating}\")\n",
    "print(f\"   Assessment: {efficiency_desc}\")\n",
    "\n",
    "# Load balancing analysis\n",
    "print(f\"\\nLOAD BALANCING ANALYSIS:\")\n",
    "if num_cores == 2:\n",
    "    instructions_per_thread = total_instructions // num_cores\n",
    "    print(f\"   Average Instructions per Thread: {instructions_per_thread:,}\")\n",
    "    \n",
    "    # Estimate load balance (perfect would be equal distribution)\n",
    "    load_balance_quality = \"Perfect\" if parallel_efficiency > 85 else \"Good\" if parallel_efficiency > 70 else \"Unbalanced\"\n",
    "    print(f\"   Load Balance Quality: {load_balance_quality}\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "multicore_data = {\n",
    "    \"Metric\": [\n",
    "        \"Number of Cores\",\n",
    "        \"Total Cycles\",\n",
    "        \"Total Instructions\",\n",
    "        \"Combined IPC\",\n",
    "        \"Parallel Efficiency (%)\",\n",
    "        \"Scaling Factor\",\n",
    "        \"L1 I-Cache Hit Rate (%)\",\n",
    "        \"L1 D-Cache Hit Rate (%)\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        f\"{num_cores}\",\n",
    "        f\"{total_cycles:,}\",\n",
    "        f\"{total_instructions:,}\",\n",
    "        f\"{combined_ipc:.3f}\",\n",
    "        f\"{parallel_efficiency:.1f}\",\n",
    "        f\"{scaling_factor:.2f}x\",\n",
    "        f\"{l1_icache_hit_rate:.2f}\",\n",
    "        f\"{l1_dcache_hit_rate:.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "multicore_df = pd.DataFrame(multicore_data)\n",
    "display(multicore_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e50b2",
   "metadata": {},
   "source": [
    "## Advanced Multicore Analysis\n",
    "\n",
    "Let's dive deeper into multicore-specific performance characteristics and optimization opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e10bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Multicore Performance Insights\n",
    "print(\"ADVANCED MULTICORE OPTIMIZATION INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"THREAD EFFICIENCY ANALYSIS:\")\n",
    "\n",
    "# Thread efficiency insights\n",
    "if parallel_efficiency > 90:\n",
    "    print(\"   Outstanding thread coordination and minimal overhead\")\n",
    "    print(\"   Recommendation: Consider scaling to more cores for increased throughput\")\n",
    "elif parallel_efficiency > 80:\n",
    "    print(\"   Good parallel scaling with acceptable overhead\")\n",
    "    print(\"   Recommendation: Minor optimizations could improve efficiency further\")\n",
    "else:\n",
    "    print(\"   Significant parallel overhead detected\")\n",
    "    print(\"   Recommendation: Investigate synchronization, memory contention, or load imbalance\")\n",
    "\n",
    "print(f\"\\nCACHE SHARING ANALYSIS:\")\n",
    "\n",
    "# Cache performance under parallel load\n",
    "if l1_icache_hit_rate > 99 and l1_dcache_hit_rate > 99:\n",
    "    print(\"   Excellent cache performance maintained under parallel load\")\n",
    "    print(\"   Recommendation: Memory access patterns are cache-friendly across threads\")\n",
    "elif l1_icache_hit_rate > 95 and l1_dcache_hit_rate > 95:\n",
    "    print(\"   Good cache utilization with minimal thread interference\")\n",
    "    print(\"   Recommendation: Consider data partitioning optimizations\")\n",
    "else:\n",
    "    print(\"   Cache performance degraded under parallel load\")\n",
    "    print(\"   Recommendation: Optimize data access patterns to reduce cache conflicts\")\n",
    "\n",
    "print(f\"\\nSCALING RECOMMENDATIONS:\")\n",
    "\n",
    "if parallel_efficiency > 85:\n",
    "    print(\"   Ready for aggressive scaling to 4+ cores\")\n",
    "    print(\"   Next experiment: Try I8500_(4_threads) configuration\")\n",
    "    print(\"   Expected outcome: Strong performance gains with more cores\")\n",
    "elif parallel_efficiency > 70:\n",
    "    print(\"   Moderate scaling potential to 4 cores\")\n",
    "    print(\"   Recommendation: Optimize current 2-core performance before scaling up\")\n",
    "    print(\"   Focus areas: Load balancing and cache optimization\")\n",
    "else:\n",
    "    print(\"   Address parallel bottlenecks before scaling up\")\n",
    "    print(\"   Investigation needed: Thread synchronization and memory access patterns\")\n",
    "    print(\"   Consider: Workload partitioning strategies\")\n",
    "\n",
    "print(f\"\\nMULTICORE OPTIMIZATION STRATEGIES:\")\n",
    "print(\"   â€¢ Thread Affinity: Pin threads to specific cores\")\n",
    "print(\"   â€¢ Data Locality: Minimize cross-thread memory sharing\")\n",
    "print(\"   â€¢ Load Balancing: Ensure equal work distribution\")\n",
    "print(\"   â€¢ Cache Optimization: Reduce false sharing between threads\")\n",
    "print(\"   â€¢ NUMA Awareness: Consider memory topology for larger systems\")\n",
    "\n",
    "print(f\"\\nComplete multicore analysis saved to: {results_dir}/{experiment_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e66551",
   "metadata": {},
   "source": [
    "## Multicore Analysis Summary\n",
    "\n",
    "**Excellent work!** You've successfully completed a comprehensive multicore performance analysis using Atlas Explorer 3.0.\n",
    "\n",
    "### What You Accomplished:\n",
    "- Configured Atlas Explorer 3.0 for multicore analysis\n",
    "- Ran parallel workloads across multiple threads\n",
    "- Analyzed parallel efficiency and scaling characteristics\n",
    "- Evaluated thread load balancing and cache sharing\n",
    "- Generated advanced multicore optimization insights\n",
    "\n",
    "### Advanced Experiments to Try:\n",
    "1. **Scale Up**: Try `I8500_(4_threads)` for quad-core analysis\n",
    "2. **Compare Configurations**: Run same workloads on different core counts\n",
    "3. **Optimize Workloads**: Test with `-O3` optimized ELF files\n",
    "4. **Custom Workloads**: Analyze your own parallel applications\n",
    "5. **Scaling Studies**: Create performance scaling curves\n",
    "\n",
    "### Research Opportunities:\n",
    "- **Parallel Overhead Analysis**: Quantify coordination costs\n",
    "- **Cache Coherency Studies**: Analyze inter-thread cache behavior\n",
    "- **NUMA Performance**: Study memory topology effects\n",
    "- **Workload Characterization**: Profile different parallel patterns\n",
    "\n",
    "### Continue Learning:\n",
    "- [Command-line automation](../examples/)\n",
    "- [Single-core analysis](ae_singlecore_notebook.ipynb)\n",
    "- [Full documentation](../README.md)\n",
    "- [Advanced configuration options](../README.md#configuration-guide)\n",
    "\n",
    "**Congratulations on mastering multicore performance analysis with Atlas Explorer 3.0!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23245852",
   "metadata": {},
   "source": [
    "# ğŸš€ ATLAS Explorer 3.0 - Multicore Performance Analysis\n",
    "\n",
    "This notebook demonstrates **multicore CPU performance analysis** using the Atlas Explorer 3.0 modular architecture.\n",
    "\n",
    "## ğŸ“š What You'll Master\n",
    "- ğŸ–¥ï¸ Thread load balancing and parallel efficiency\n",
    "- âš¡ Resource contention analysis and optimization\n",
    "- ğŸ“Š Scaling studies across different core counts  \n",
    "- ğŸ”„ Cache sharing and memory system behavior\n",
    "- ğŸš€ Advanced multicore optimization techniques\n",
    "\n",
    "## ğŸ¯ Prerequisites\n",
    "- Atlas Explorer credentials configured (`atlasexplorer configure`)\n",
    "- Package installed with notebook dependencies (`uv pip install -e '.[notebooks]'`)\n",
    "- Familiarity with single-core analysis (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š Import Required Libraries for Multicore Analysis\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Atlas Explorer 3.0 modular imports\n",
    "from atlasexplorer.core.client import AtlasExplorer\n",
    "from atlasexplorer.core.experiment import Experiment\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(\"ğŸš€ Atlas Explorer 3.0 - Ready for multicore analysis\")\n",
    "print(\"ğŸ–¥ï¸ Parallel computing performance insights coming up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc6e66b",
   "metadata": {},
   "source": [
    "## ğŸ”§ Configuration Check\n",
    "\n",
    "Let's verify that your Atlas Explorer credentials are properly configured for multicore experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba17f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ Check Atlas Explorer Configuration for Multicore\n",
    "print(\"ğŸ”§ Checking Atlas Explorer Configuration for Multicore...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Initialize Atlas Explorer client\n",
    "    ae = AtlasExplorer(channel=\"development\", verbose=True)\n",
    "    \n",
    "    print(\"âœ… Configuration Status: READY FOR MULTICORE\")\n",
    "    print(f\"ğŸŒ Gateway: {ae.config.gateway}\")\n",
    "    print(f\"ğŸ“¡ Channel: {ae.config.channel}\")\n",
    "    print(f\"ğŸŒ Region: {ae.config.region}\")\n",
    "    print(f\"ğŸ”‘ API Key: {ae.config.apikey[:8]}...\")\n",
    "    print(\"ğŸ–¥ï¸ Ready for parallel computing analysis!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"âŒ Configuration Error:\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nğŸ’¡ To fix this, run: atlasexplorer configure\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c70980",
   "metadata": {},
   "source": [
    "## ğŸ“ Experiment History\n",
    "\n",
    "Let's check your previous experiments to see any multicore analysis history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc951d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ Display Previous Multicore Experiments\n",
    "print(\"ğŸ“ Previous Atlas Explorer Experiments:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "experiment_dir = Path(\"myexperiments\")\n",
    "experiments = []\n",
    "\n",
    "if experiment_dir.exists():\n",
    "    for exp_path in experiment_dir.iterdir():\n",
    "        if exp_path.is_dir():\n",
    "            config_file = exp_path / \"config.json\"\n",
    "            if config_file.exists():\n",
    "                try:\n",
    "                    with open(config_file) as f:\n",
    "                        config = json.load(f)\n",
    "                    \n",
    "                    mod_time = datetime.fromtimestamp(exp_path.stat().st_mtime)\n",
    "                    core_config = config.get(\"core\", \"unknown\")\n",
    "                    \n",
    "                    experiments.append({\n",
    "                        \"Experiment\": exp_path.name,\n",
    "                        \"Channel\": config.get(\"channel\", \"unknown\"),\n",
    "                        \"Core\": core_config,\n",
    "                        \"Type\": \"Multicore\" if \"thread\" in core_config and not \"1_thread\" in core_config else \"Single-core\",\n",
    "                        \"Modified\": mod_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    })\n",
    "                except (json.JSONDecodeError, KeyError):\n",
    "                    continue\n",
    "\n",
    "if experiments:\n",
    "    df = pd.DataFrame(experiments).sort_values(\"Modified\", ascending=False)\n",
    "    display(df)\n",
    "    \n",
    "    multicore_count = sum(1 for exp in experiments if \"Multicore\" in exp[\"Type\"])\n",
    "    print(f\"\\nğŸ“Š Found {len(experiments)} total experiments ({multicore_count} multicore)\")\n",
    "else:\n",
    "    print(\"No previous experiments found. This will be your first multicore experiment!\")\n",
    "    print(\"ğŸ†• Creating 'myexperiments' directory for results...\")\n",
    "    experiment_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d012bbee",
   "metadata": {},
   "source": [
    "## ğŸ–¥ï¸ Multicore Experiment Setup\n",
    "\n",
    "Now let's set up a multicore experiment using multiple workloads to analyze parallel performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7831f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ–¥ï¸ Multicore Experiment Configuration\n",
    "print(\"ğŸ–¥ï¸ Setting up Multicore Performance Experiment\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Experiment parameters\n",
    "elf_files = [\n",
    "    \"resources/mandelbrot_rv64_O0.elf\",\n",
    "    \"resources/memcpy_rv64.elf\"\n",
    "]\n",
    "core_config = \"I8500_(2_threads)\"  # 2-core configuration\n",
    "experiment_name = \"multicore_parallel_analysis\"\n",
    "results_dir = \"myexperiments\"\n",
    "\n",
    "print(f\"ğŸ“ ELF Files:\")\n",
    "for i, elf_file in enumerate(elf_files, 1):\n",
    "    print(f\"   {i}. {elf_file}\")\n",
    "print(f\"ğŸ–¥ï¸ Core Configuration: {core_config}\")\n",
    "print(f\"ğŸ“Š Experiment Name: {experiment_name}\")\n",
    "print(f\"ğŸ’¾ Results Directory: {results_dir}\")\n",
    "\n",
    "# Verify all ELF files exist\n",
    "missing_files = []\n",
    "for elf_file in elf_files:\n",
    "    if not os.path.exists(elf_file):\n",
    "        missing_files.append(elf_file)\n",
    "    else:\n",
    "        print(f\"âœ… Verified: {elf_file}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"âŒ Error: Missing ELF files: {missing_files}\")\n",
    "    print(\"ğŸ’¡ Make sure you're running from the repository root directory\")\n",
    "    raise FileNotFoundError(f\"ELF files not found: {missing_files}\")\n",
    "    \n",
    "print(\"\\nğŸš€ Ready to launch multicore experiment!\")\n",
    "print(f\"ğŸ§µ This will analyze parallel execution across {core_config.split('_')[1].replace('(', '').replace(')', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c26502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Launch Multicore Experiment\n",
    "print(\"ğŸš€ Launching Multicore Performance Analysis...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Create experiment\n",
    "    experiment = Experiment(experiment_name, ae)\n",
    "    \n",
    "    # Configure experiment with multiple workloads\n",
    "    for elf_file in elf_files:\n",
    "        experiment.addWorkload(elf_file)\n",
    "    \n",
    "    experiment.setCore(core_config)\n",
    "    experiment.setResultsDir(results_dir)\n",
    "    \n",
    "    print(f\"ğŸ“‹ Multicore experiment configured:\")\n",
    "    print(f\"   â€¢ Name: {experiment_name}\")\n",
    "    print(f\"   â€¢ Workloads: {len(elf_files)} parallel tasks\")\n",
    "    for i, elf_file in enumerate(elf_files, 1):\n",
    "        print(f\"     {i}. {os.path.basename(elf_file)}\")\n",
    "    print(f\"   â€¢ Core: {core_config}\")\n",
    "    print(f\"   â€¢ Channel: {ae.config.channel}\")\n",
    "    \n",
    "    # Run experiment\n",
    "    print(\"\\nâ³ Running multicore experiment... (this may take 2-5 minutes)\")\n",
    "    print(\"ğŸ§µ Analyzing parallel execution, thread load balancing, and resource sharing...\")\n",
    "    experiment.run()\n",
    "    \n",
    "    print(\"\\nâœ… Multicore experiment completed successfully!\")\n",
    "    print(f\"ğŸ“ Results saved to: {results_dir}/{experiment_name}/\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Experiment failed: {e}\")\n",
    "    print(\"ğŸ’¡ Check your network connection and credentials\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003994e7",
   "metadata": {},
   "source": [
    "## ğŸ“Š Multicore Performance Results\n",
    "\n",
    "Now let's analyze the parallel performance results and thread efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137557a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Extract and Display Multicore Performance Metrics\n",
    "print(\"ğŸ“Š MULTICORE PERFORMANCE ANALYSIS RESULTS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Get experiment summary\n",
    "summary = experiment.getSummary()\n",
    "\n",
    "# Overall performance metrics\n",
    "total_cycles = summary.getTotalCycles()\n",
    "total_instructions = summary.getTotalInstructions()\n",
    "combined_ipc = summary.getIPC()\n",
    "l1_icache_hit_rate = summary.getL1InstructionCacheHitRate()\n",
    "l1_dcache_hit_rate = summary.getL1DataCacheHitRate()\n",
    "\n",
    "print(f\"ğŸ¯ OVERALL MULTICORE RESULTS:\")\n",
    "print(f\"   Total Cycles: {total_cycles:,}\")\n",
    "print(f\"   Instructions Executed: {total_instructions:,}\")\n",
    "print(f\"   Combined IPC: {combined_ipc:.3f}\")\n",
    "print(f\"\\nğŸ’¾ SHARED CACHE PERFORMANCE:\")\n",
    "print(f\"   L1 Instruction Cache Hit Rate: {l1_icache_hit_rate:.2f}%\")\n",
    "print(f\"   L1 Data Cache Hit Rate: {l1_dcache_hit_rate:.2f}%\")\n",
    "\n",
    "# Try to get per-thread metrics if available\n",
    "print(f\"\\nğŸ§µ THREAD-LEVEL ANALYSIS:\")\n",
    "try:\n",
    "    # This may vary depending on the exact API\n",
    "    thread_metrics = summary.getThreadMetrics() if hasattr(summary, 'getThreadMetrics') else None\n",
    "    if thread_metrics:\n",
    "        for i, thread in enumerate(thread_metrics):\n",
    "            print(f\"   Thread {i}: {thread['instructions']:,} instructions, IPC: {thread['ipc']:.3f}\")\n",
    "    else:\n",
    "        # Estimate thread distribution\n",
    "        estimated_instructions_per_thread = total_instructions // len(elf_files)\n",
    "        estimated_ipc_per_thread = combined_ipc / len(elf_files)\n",
    "        \n",
    "        for i in range(len(elf_files)):\n",
    "            print(f\"   Thread {i} (estimated): ~{estimated_instructions_per_thread:,} instructions, IPC: ~{estimated_ipc_per_thread:.3f}\")\n",
    "        print(f\"   ğŸ“ Note: Per-thread metrics estimated from combined results\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ Individual thread metrics not available: {e}\")\n",
    "    print(f\"   ğŸ“Š Combined metrics shown above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ˆ Parallel Efficiency Analysis\n",
    "print(\"ğŸ“ˆ PARALLEL EFFICIENCY & SCALING ANALYSIS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Calculate parallel efficiency metrics\n",
    "num_cores = len(elf_files)\n",
    "theoretical_max_ipc = num_cores  # Theoretical maximum if perfect scaling\n",
    "\n",
    "# Parallel efficiency calculation\n",
    "parallel_efficiency = (combined_ipc / theoretical_max_ipc) * 100\n",
    "scaling_factor = combined_ipc\n",
    "\n",
    "print(f\"ğŸ–¥ï¸ PARALLEL COMPUTING METRICS:\")\n",
    "print(f\"   Number of Cores/Threads: {num_cores}\")\n",
    "print(f\"   Combined IPC: {combined_ipc:.3f}\")\n",
    "print(f\"   Theoretical Maximum IPC: {theoretical_max_ipc:.1f}\")\n",
    "print(f\"   Parallel Efficiency: {parallel_efficiency:.1f}%\")\n",
    "print(f\"   Scaling Factor: {scaling_factor:.2f}x\")\n",
    "\n",
    "# Performance rating\n",
    "if parallel_efficiency > 90:\n",
    "    efficiency_rating = \"ğŸŒŸ Excellent\"\n",
    "    efficiency_desc = \"Outstanding parallel scaling\"\n",
    "elif parallel_efficiency > 80:\n",
    "    efficiency_rating = \"âœ… Very Good\"\n",
    "    efficiency_desc = \"Strong parallel performance\"\n",
    "elif parallel_efficiency > 60:\n",
    "    efficiency_rating = \"âš ï¸ Good\"\n",
    "    efficiency_desc = \"Reasonable parallel scaling with room for improvement\"\n",
    "else:\n",
    "    efficiency_rating = \"âŒ Needs Improvement\"\n",
    "    efficiency_desc = \"Poor parallel scaling - investigate bottlenecks\"\n",
    "\n",
    "print(f\"\\nğŸ¯ EFFICIENCY ASSESSMENT:\")\n",
    "print(f\"   Rating: {efficiency_rating}\")\n",
    "print(f\"   Assessment: {efficiency_desc}\")\n",
    "\n",
    "# Load balancing analysis\n",
    "print(f\"\\nâš–ï¸ LOAD BALANCING ANALYSIS:\")\n",
    "if num_cores == 2:\n",
    "    instructions_per_thread = total_instructions // num_cores\n",
    "    print(f\"   Average Instructions per Thread: {instructions_per_thread:,}\")\n",
    "    \n",
    "    # Estimate load balance (perfect would be equal distribution)\n",
    "    load_balance_quality = \"ğŸ† Perfect\" if parallel_efficiency > 85 else \"âœ… Good\" if parallel_efficiency > 70 else \"âš ï¸ Unbalanced\"\n",
    "    print(f\"   Load Balance Quality: {load_balance_quality}\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "multicore_data = {\n",
    "    \"Metric\": [\n",
    "        \"ğŸ–¥ï¸ Number of Cores\",\n",
    "        \"ğŸ¯ Total Cycles\",\n",
    "        \"ğŸ“Š Total Instructions\",\n",
    "        \"âš¡ Combined IPC\",\n",
    "        \"ğŸ“ˆ Parallel Efficiency (%)\",\n",
    "        \"ğŸš€ Scaling Factor\",\n",
    "        \"ğŸ’¾ L1 I-Cache Hit Rate (%)\",\n",
    "        \"ğŸ’¾ L1 D-Cache Hit Rate (%)\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        f\"{num_cores}\",\n",
    "        f\"{total_cycles:,}\",\n",
    "        f\"{total_instructions:,}\",\n",
    "        f\"{combined_ipc:.3f}\",\n",
    "        f\"{parallel_efficiency:.1f}\",\n",
    "        f\"{scaling_factor:.2f}x\",\n",
    "        f\"{l1_icache_hit_rate:.2f}\",\n",
    "        f\"{l1_dcache_hit_rate:.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "multicore_df = pd.DataFrame(multicore_data)\n",
    "display(multicore_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e72361",
   "metadata": {},
   "source": [
    "## ğŸ” Advanced Multicore Analysis\n",
    "\n",
    "Let's dive deeper into multicore-specific performance characteristics and optimization opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Advanced Multicore Performance Insights\n",
    "print(\"ğŸ” ADVANCED MULTICORE OPTIMIZATION INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"ğŸ§µ THREAD EFFICIENCY ANALYSIS:\")\n",
    "\n",
    "# Thread efficiency insights\n",
    "if parallel_efficiency > 90:\n",
    "    print(\"   ğŸŒŸ Outstanding thread coordination and minimal overhead\")\n",
    "    print(\"   ğŸ’¡ Consider scaling to more cores for increased throughput\")\n",
    "elif parallel_efficiency > 80:\n",
    "    print(\"   âœ… Good parallel scaling with acceptable overhead\")\n",
    "    print(\"   ğŸ’¡ Minor optimizations could improve efficiency further\")\n",
    "else:\n",
    "    print(\"   âš ï¸ Significant parallel overhead detected\")\n",
    "    print(\"   ğŸ’¡ Investigate synchronization, memory contention, or load imbalance\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ CACHE SHARING ANALYSIS:\")\n",
    "\n",
    "# Cache performance under parallel load\n",
    "if l1_icache_hit_rate > 99 and l1_dcache_hit_rate > 99:\n",
    "    print(\"   ğŸŒŸ Excellent cache performance maintained under parallel load\")\n",
    "    print(\"   ğŸ’¡ Memory access patterns are cache-friendly across threads\")\n",
    "elif l1_icache_hit_rate > 95 and l1_dcache_hit_rate > 95:\n",
    "    print(\"   âœ… Good cache utilization with minimal thread interference\")\n",
    "    print(\"   ğŸ’¡ Consider data partitioning optimizations\")\n",
    "else:\n",
    "    print(\"   âš ï¸ Cache performance degraded under parallel load\")\n",
    "    print(\"   ğŸ’¡ Optimize data access patterns to reduce cache conflicts\")\n",
    "\n",
    "print(f\"\\nğŸš€ SCALING RECOMMENDATIONS:\")\n",
    "\n",
    "if parallel_efficiency > 85:\n",
    "    print(\"   ğŸ¯ Ready for aggressive scaling to 4+ cores\")\n",
    "    print(\"   ğŸ’¡ Try I8500_(4_threads) configuration for next experiment\")\n",
    "    print(\"   ğŸ“ˆ Expect strong performance gains with more cores\")\n",
    "elif parallel_efficiency > 70:\n",
    "    print(\"   âš¡ Moderate scaling potential to 4 cores\")\n",
    "    print(\"   ğŸ’¡ Optimize current 2-core performance before scaling up\")\n",
    "    print(\"   ğŸ”§ Focus on load balancing and cache optimization\")\n",
    "else:\n",
    "    print(\"   âš ï¸ Address parallel bottlenecks before scaling up\")\n",
    "    print(\"   ğŸ’¡ Investigate thread synchronization and memory access patterns\")\n",
    "    print(\"   ğŸ”§ Consider workload partitioning strategies\")\n",
    "\n",
    "print(f\"\\nğŸ† MULTICORE OPTIMIZATION STRATEGIES:\")\n",
    "print(\"   â€¢ ğŸ§µ Thread Affinity: Pin threads to specific cores\")\n",
    "print(\"   â€¢ ğŸ’¾ Data Locality: Minimize cross-thread memory sharing\")\n",
    "print(\"   â€¢ âš–ï¸ Load Balancing: Ensure equal work distribution\")\n",
    "print(\"   â€¢ ğŸ”„ Cache Optimization: Reduce false sharing between threads\")\n",
    "print(\"   â€¢ ğŸ“Š NUMA Awareness: Consider memory topology for larger systems\")\n",
    "\n",
    "print(f\"\\nğŸ“ Complete multicore analysis saved to: {results_dir}/{experiment_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff528d",
   "metadata": {},
   "source": [
    "## ğŸ Multicore Analysis Summary\n",
    "\n",
    "**Excellent work!** You've successfully completed a comprehensive multicore performance analysis using Atlas Explorer 3.0.\n",
    "\n",
    "### ğŸ“‹ What You Accomplished:\n",
    "- âœ… Configured Atlas Explorer 3.0 for multicore analysis\n",
    "- âœ… Ran parallel workloads across multiple threads\n",
    "- âœ… Analyzed parallel efficiency and scaling characteristics\n",
    "- âœ… Evaluated thread load balancing and cache sharing\n",
    "- âœ… Generated advanced multicore optimization insights\n",
    "\n",
    "### ğŸš€ Advanced Experiments to Try:\n",
    "1. **Scale Up**: Try `I8500_(4_threads)` for quad-core analysis\n",
    "2. **Compare Configurations**: Run same workloads on different core counts\n",
    "3. **Optimize Workloads**: Test with `-O3` optimized ELF files\n",
    "4. **Custom Workloads**: Analyze your own parallel applications\n",
    "5. **Scaling Studies**: Create performance scaling curves\n",
    "\n",
    "### ğŸ”¬ Research Opportunities:\n",
    "- **Parallel Overhead Analysis**: Quantify coordination costs\n",
    "- **Cache Coherency Studies**: Analyze inter-thread cache behavior\n",
    "- **NUMA Performance**: Study memory topology effects\n",
    "- **Workload Characterization**: Profile different parallel patterns\n",
    "\n",
    "### ğŸ“š Continue Learning:\n",
    "- ğŸ“– [Command-line automation](../examples/)\n",
    "- ğŸ”¬ [Single-core analysis](ae_singlecore_notebook.ipynb)\n",
    "- ğŸ“Š [Full documentation](../README.md)\n",
    "- ğŸ—ï¸ [Advanced configuration options](../README.md#configuration-guide)\n",
    "\n",
    "**ğŸ‰ Congratulations on mastering multicore performance analysis with Atlas Explorer 3.0!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
