{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec330c2",
   "metadata": {},
   "source": [
    "# ATLAS Explorer: Single-Core Experiment\n",
    "\n",
    "Welcome! This guided notebook walks you through running a *single-core* ATLAS Explorer experiment.\n",
    "\n",
    "You will:\n",
    "1. Verify prerequisites\n",
    "2. Configure (or auto-detect) your credentials\n",
    "3. Set a few experiment parameters (file, core type, etc.)\n",
    "4. Run the experiment\n",
    "5. View key results (Total Cycles + summary table)\n",
    "6. (Optional) Explore derived metrics\n",
    "\n",
    "Tips:\n",
    "- Edit only the clearly marked parameter cells (grey code boxes with simple assignments)\n",
    "- Reâ€‘run a cell with Shift+Enter\n",
    "- If something fails, read the printed message and adjust the parameters\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da16f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment initialized. Proceed to the next cell.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ğŸš€ ATLAS Explorer Single-Core Analysis - Getting Started\n",
    "\n",
    "Welcome to ATLAS Explorer! This notebook is your step-by-step guide to running \n",
    "performance analysis on single-core processor workloads.\n",
    "\n",
    "What you'll learn:\n",
    "â€¢ How to set up and configure ATLAS Explorer\n",
    "â€¢ Running performance experiments on CPU cores\n",
    "â€¢ Analyzing key metrics like cycles, instructions, and IPC\n",
    "â€¢ Understanding bottlenecks and optimization opportunities\n",
    "\n",
    "ğŸ’¡ Beginner Tips:\n",
    "- Green text = successful operations\n",
    "- Red text = errors (read carefully for solutions)  \n",
    "- Each cell builds on the previous one - run them in order\n",
    "- Don't worry about the code details - focus on the results!\n",
    "\n",
    "Let's start by importing the necessary libraries...\n",
    "\"\"\"\n",
    "import os, json, locale, datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd  # used for tabular display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load any .env for convenience (optional)\n",
    "load_dotenv()\n",
    "locale.setlocale(locale.LC_ALL, \"\")\n",
    "\n",
    "print(\"âœ… Environment initialized successfully!\")\n",
    "print(\"ğŸ“ Next step: Run the next cell to check your project setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a52ac6a",
   "metadata": {},
   "source": [
    "## 1. Check Project & Existing Experiments\n",
    "\n",
    "ğŸ“ **What this does:** Ensures you're in the right directory and shows any previous experiment results.\n",
    "\n",
    "This cell will:\n",
    "- Automatically find your project root directory \n",
    "- List any prior experiment runs stored in `myexperiments/` folder\n",
    "- Show you when each experiment was last modified\n",
    "\n",
    "**For beginners:** Think of this as checking your workspace - like opening the right folder before starting work. If you see previous experiments listed, that's normal and helpful for reference!\n",
    "\n",
    "âœ¨ **Just click \"Run\" below - no editing needed!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ab2bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to repo root: /Users/jschroeder/Documents/code_repos/mips-ae-pylib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I8500_(2_threads)_250808_103012</td>\n",
       "      <td>/Users/jschroeder/Documents/code_repos/mips-ae...</td>\n",
       "      <td>2025-08-08T10:34:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I8500_(1_thread)_250808_102301</td>\n",
       "      <td>/Users/jschroeder/Documents/code_repos/mips-ae...</td>\n",
       "      <td>2025-08-08T10:27:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  \\\n",
       "1  I8500_(2_threads)_250808_103012   \n",
       "0   I8500_(1_thread)_250808_102301   \n",
       "\n",
       "                                             summary             modified  \n",
       "1  /Users/jschroeder/Documents/code_repos/mips-ae...  2025-08-08T10:34:36  \n",
       "0  /Users/jschroeder/Documents/code_repos/mips-ae...  2025-08-08T10:27:58  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (No edits needed) Detect repo root and list existing experiment runs.\n",
    "from pathlib import Path\n",
    "import os, datetime\n",
    "\n",
    "cwd = Path.cwd()\n",
    "repo_root = None\n",
    "for p in [cwd, *cwd.parents]:\n",
    "    if (p / \"pyproject.toml\").exists() or (p / \".git\").exists():\n",
    "        repo_root = p\n",
    "        break\n",
    "repo_root = repo_root or cwd\n",
    "os.chdir(repo_root)\n",
    "print(f\"Working directory set to repo root: {repo_root}\")\n",
    "\n",
    "exp_root = repo_root / \"myexperiments\"\n",
    "rows = []\n",
    "if exp_root.exists():\n",
    "    for run_dir in sorted(exp_root.iterdir()):\n",
    "        if run_dir.is_dir():\n",
    "            summary = next(run_dir.rglob(\"reports/summary/summary.json\"), None)\n",
    "            mtime = datetime.datetime.fromtimestamp(run_dir.stat().st_mtime)\n",
    "            rows.append({\n",
    "                \"name\": run_dir.name,\n",
    "                \"summary\": str(summary) if summary else \"-\",\n",
    "                \"modified\": mtime.isoformat(timespec=\"seconds\"),\n",
    "            })\n",
    "    if not rows:\n",
    "        print(\"No experiments found yet under 'myexperiments'.\")\n",
    "else:\n",
    "    print(\"No 'myexperiments' directory found yet.\")\n",
    "\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows).sort_values(\"modified\", ascending=False)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0620e70d",
   "metadata": {},
   "source": [
    "## Project root & experiments\n",
    "This notebook will first switch the working directory to the repository root and list any existing experiments under `myexperiments/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91c223",
   "metadata": {},
   "source": [
    "## 2. Configure Credentials\n",
    "\n",
    "ğŸ” **What this does:** Sets up your connection to ATLAS Explorer's cloud services.\n",
    "\n",
    "**Think of this like logging into your account.** ATLAS Explorer needs three pieces of information:\n",
    "- **API Key:** Your unique identifier (like a password)\n",
    "- **Channel:** Which environment to use (usually \"development\" for testing)\n",
    "- **Region:** Which data center to connect to (e.g., \"us-west-2\")\n",
    "\n",
    "The system will automatically look for your credentials in two places:\n",
    "1. Environment variable `MIPS_ATLAS_CONFIG` (format: apikey:channel:region)  \n",
    "2. Config file at `~/.config/mips/atlaspy/config.json`\n",
    "\n",
    "**For beginners:** If this is your first time, you'll need to enter your credentials when prompted. Don't worry - the system will guide you through it and can save them for next time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa86f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials detected from environment variable MIPS_ATLAS_CONFIG.\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” CREDENTIAL SETUP - Run this cell first, then follow the instructions\n",
    "from pathlib import Path\n",
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "CONFIG_ENV = \"MIPS_ATLAS_CONFIG\"\n",
    "cfg_file = Path.home() / \".config/mips/atlaspy/config.json\"\n",
    "\n",
    "print(\"ğŸ” Checking for existing credentials...\")\n",
    "\n",
    "if os.environ.get(CONFIG_ENV):\n",
    "    print(\"âœ… Credentials detected from environment variable MIPS_ATLAS_CONFIG.\")\n",
    "elif cfg_file.exists():\n",
    "    try:\n",
    "        data = json.loads(cfg_file.read_text())\n",
    "        os.environ[CONFIG_ENV] = f\"{data['apikey']}:{data['channel']}:{data['region']}\"\n",
    "        print(f\"âœ… Credentials loaded from {cfg_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Could not parse {cfg_file}: {e}\")\n",
    "\n",
    "if not os.environ.get(CONFIG_ENV):\n",
    "    print(\"\\nğŸ”‘ NO CREDENTIALS FOUND\")\n",
    "    print(\"ğŸ‘‡ PLEASE FILL IN YOUR CREDENTIALS BELOW, then re-run this cell:\")\n",
    "    print(\"   (Ask your system administrator if you don't have these)\")\n",
    "    \n",
    "    # ğŸ“ EDIT THESE VALUES - Replace the empty strings with your actual credentials\n",
    "    ae_apikey   = \"\"  # â† PUT YOUR API KEY HERE (between the quotes)\n",
    "    ae_channel  = \"development\"  # â† Usually keep as \"development\" for testing\n",
    "    ae_region   = \"\"  # â† PUT YOUR REGION HERE (e.g., \"us-west-2\")\n",
    "    persist_to_file = True  # â† Set to False if you don't want to save credentials\n",
    "\n",
    "    if not ae_apikey or not ae_channel or not ae_region:\n",
    "        print(\"\\nâ³ Waiting for your input...\")\n",
    "        print(\"ğŸ’¡ Fill in ae_apikey, ae_channel, and ae_region above, then run this cell again\")\n",
    "    else:\n",
    "        os.environ[CONFIG_ENV] = f\"{ae_apikey}:{ae_channel}:{ae_region}\"\n",
    "        print(\"âœ… Session credentials set successfully!\")\n",
    "        if persist_to_file:\n",
    "            cfg_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            cfg_file.write_text(json.dumps({\"apikey\": ae_apikey, \"channel\": ae_channel, \"region\": ae_region}, indent=2))\n",
    "            print(f\"ğŸ’¾ Credentials saved to {cfg_file} for future use\")\n",
    "else:\n",
    "    print(\"âœ… Ready to proceed with experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f992fae",
   "metadata": {},
   "source": [
    "## 3. Experiment Overview\n",
    "\n",
    "ğŸ§ª **What we're doing:** Running a performance analysis on a single CPU core with a test program.\n",
    "\n",
    "**In simple terms:** We'll take a small program (called an \"ELF file\") and run it on a virtual CPU core to see how it performs. This is like having a high-tech stopwatch that measures not just time, but also:\n",
    "\n",
    "- **Cycles:** How many clock ticks the program took\n",
    "- **Instructions:** How many individual operations were executed  \n",
    "- **IPC (Instructions Per Cycle):** How efficiently the CPU worked\n",
    "- **Memory usage:** How the program used cache and RAM\n",
    "- **Bottlenecks:** Where the program might be slowing down\n",
    "\n",
    "**For beginners:** Think of this like a diagnostic test for your program - we're measuring its \"vital signs\" to understand how healthy and efficient it is!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b31519",
   "metadata": {},
   "source": [
    "### Prerequisites Checklist âœ…\n",
    "\n",
    "Before running your experiment, make sure you have:\n",
    "\n",
    "- âœ… **Credentials configured** (completed in step 2 above)\n",
    "- âœ… **Test program available** (we provide a sample program called `mandelbrot_rv64_O0.elf`)\n",
    "- âœ… **Core configuration chosen** (we'll use a standard I8500 single-threaded core)\n",
    "\n",
    "**For beginners:** The default settings are perfect for your first experiment! The sample program we're using generates a mathematical pattern called a Mandelbrot set - it's computationally intensive, making it perfect for performance testing.\n",
    "\n",
    "**Advanced users:** Feel free to substitute your own ELF files or try different core configurations in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f128e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters set. Modify above as needed.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ›ï¸ EXPERIMENT PARAMETERS - Beginners can use defaults, advanced users can customize\n",
    "\n",
    "print(\"âš™ï¸ Setting up experiment parameters...\")\n",
    "print(\"ğŸ’¡ Beginners: The default values below are perfect for your first run!\")\n",
    "print(\"ğŸ”§ Advanced: Feel free to modify any of these parameters\\n\")\n",
    "\n",
    "# ğŸ“ WORKLOAD: Which program to analyze\n",
    "elf = \"resources/mandelbrot_rv64_O0.elf\"   # Path to test program (Mandelbrot fractal generator)\n",
    "print(f\"ğŸ“‹ Test program: {elf}\")\n",
    "\n",
    "# ğŸ’¾ STORAGE: Where to save results  \n",
    "expdir = \"myexperiments\"                   # Folder to store experiment results\n",
    "print(f\"ğŸ“ Results folder: {expdir}\")\n",
    "\n",
    "# ğŸ–¥ï¸ HARDWARE: What kind of CPU core to simulate\n",
    "core = \"I8500_(1_thread)\"                  # Core type: I8500 with 1 thread (good for beginners)\n",
    "print(f\"ğŸ–¥ï¸ CPU core: {core}\")\n",
    "\n",
    "# ğŸŒ CONNECTION: Cloud service settings\n",
    "channel = \"development\"                    # Environment (development = safe testing area)\n",
    "apikey = None                               # Auto-detect from previous configuration  \n",
    "region = None                               # Auto-detect from previous configuration\n",
    "print(f\"ğŸŒ Channel: {channel}\")\n",
    "\n",
    "# ğŸ” LOGGING: How much detail to show\n",
    "verbose = False                             # Set to True if you want detailed technical logs\n",
    "print(f\"ğŸ“ Verbose logging: {verbose}\")\n",
    "\n",
    "# ğŸ“¤ EXPORT: Optional output formats\n",
    "export = None                               # Options: 'json', 'markdown', 'html', 'rich-html', 'zip'\n",
    "out = None                                  # Where to save exported files (None = default location)\n",
    "\n",
    "print(f\"\\nâœ… Configuration complete! Ready to run your experiment.\")\n",
    "print(\"ğŸ‘‰ Tip: You can always come back and modify these parameters for different experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8530d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials appear available. Proceed.\n"
     ]
    }
   ],
   "source": [
    "# 3.b Environment validation (no edits needed)\n",
    "import os, locale\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "locale.setlocale(locale.LC_ALL, \"\")\n",
    "\n",
    "config_env = os.environ.get(\"MIPS_ATLAS_CONFIG\")\n",
    "config_file = Path.home() / \".config/mips/atlaspy/config.json\"\n",
    "if not apikey and not config_env and not config_file.exists():\n",
    "    print(\"NOTE: Run 'uv run atlasexplorer/atlasexplorer.py configure' or set MIPS_ATLAS_CONFIG before running.\")\n",
    "else:\n",
    "    print(\"Credentials appear available. Proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d7554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment run...\n",
      "Available versions: latest, ST-2025-07-16-171806\n",
      "No report directory found:summary\n",
      "Total Cycles: 253629\n",
      "Latest summary: myexperiments/I8500_(1_thread)_250811_105319/I8500_(1_thread)_250811_105319/reports/summary/summary.json\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ EXPERIMENT EXECUTION - This is where the magic happens!\n",
    "print(\"ğŸš€ Starting your ATLAS Explorer experiment...\")\n",
    "print(\"â±ï¸ This process involves several steps:\")\n",
    "print(\"   1. Uploading your program to ATLAS cloud\")\n",
    "print(\"   2. Running the simulation on virtual hardware\") \n",
    "print(\"   3. Analyzing performance metrics\")\n",
    "print(\"   4. Downloading detailed results\")\n",
    "print(\"\\nâŒ› Please wait - this typically takes 30 seconds to 2 minutes...\\n\")\n",
    "\n",
    "from atlasexplorer.atlasexplorer import AtlasExplorer, Experiment\n",
    "\n",
    "# Initialize ATLAS Explorer connection\n",
    "aeinst = AtlasExplorer(apikey, channel, region, verbose=verbose)\n",
    "experiment = Experiment(expdir, aeinst, verbose=verbose)\n",
    "\n",
    "# Configure the experiment\n",
    "experiment.addWorkload(os.path.abspath(elf))  # Add your program\n",
    "experiment.setCore(core)                       # Set the CPU core type\n",
    "\n",
    "# Run the experiment (this does the heavy lifting!)\n",
    "experiment.run()\n",
    "print(\"âœ… Experiment completed successfully!\")\n",
    "\n",
    "# Get the most important result: Total Cycles\n",
    "try:\n",
    "    total_cycles = experiment.getSummary().getTotalCycles()\n",
    "    print(f\"\\nğŸ¯ KEY RESULT:\")\n",
    "    print(f\"   Total Cycles: {total_cycles:,}\")\n",
    "    print(f\"   ğŸ’¡ This means your program took {total_cycles:,} clock cycles to complete\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not retrieve total cycles: {e}\")\n",
    "\n",
    "# Find the detailed results file\n",
    "from pathlib import Path\n",
    "exp_path = Path(expdir)\n",
    "summary_candidates = list(exp_path.rglob(\"summary/summary.json\"))\n",
    "if not summary_candidates:\n",
    "    raise FileNotFoundError(\"âŒ No summary.json found - experiment may have failed\")\n",
    "\n",
    "summary_candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "summary_path = summary_candidates[0]\n",
    "print(f\"\\nğŸ“Š Detailed results saved to: {summary_path}\")\n",
    "print(\"ğŸ‰ Ready to explore your performance metrics in the next cells!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab9569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistics</th>\n",
       "      <th>vis</th>\n",
       "      <th>siminfo</th>\n",
       "      <th>report_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'Summary Performance Report': {'Total Cycles ...</td>\n",
       "      <td>{'hidden': 0, 'support': 1000000, 'detail': 10...</td>\n",
       "      <td>{'name': 'Shinro RISC-V Perf Model ', 'sim_ver...</td>\n",
       "      <td>{'arch': 'I8500_(1_thread)', 'report_format': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Statistics  \\\n",
       "0  {'Summary Performance Report': {'Total Cycles ...   \n",
       "\n",
       "                                                 vis  \\\n",
       "0  {'hidden': 0, 'support': 1000000, 'detail': 10...   \n",
       "\n",
       "                                             siminfo  \\\n",
       "0  {'name': 'Shinro RISC-V Perf Model ', 'sim_ver...   \n",
       "\n",
       "                                     report_metadata  \n",
       "0  {'arch': 'I8500_(1_thread)', 'report_format': ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displayed summary (first rows if large).\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š VIEW EXPERIMENT SUMMARY - Your results at a glance\n",
    "print(\"ğŸ“‹ Loading your experiment summary...\")\n",
    "print(\"ğŸ’¡ This table shows the key metrics from your performance analysis\\n\")\n",
    "\n",
    "import json, pandas as pd\n",
    "with open(summary_path) as f:\n",
    "    summary_data = json.load(f)\n",
    "\n",
    "# Convert to readable table format\n",
    "if isinstance(summary_data, dict):\n",
    "    df = pd.DataFrame([summary_data])\n",
    "elif isinstance(summary_data, list):\n",
    "    df = pd.DataFrame(summary_data)\n",
    "else:\n",
    "    df = None\n",
    "\n",
    "if df is not None:\n",
    "    print(\"ğŸ“ˆ EXPERIMENT SUMMARY:\")\n",
    "    print(\"=\" * 50)\n",
    "    display(df.head())\n",
    "    print(\"\\nâœ¨ Key things to look for:\")\n",
    "    print(\"   â€¢ Total cycles: How long your program took\")\n",
    "    print(\"   â€¢ Instructions: How many operations were executed\")\n",
    "    print(\"   â€¢ IPC: Instructions per cycle (higher = more efficient)\")\n",
    "    print(\"   â€¢ Cache stats: Memory system performance\")\n",
    "else:\n",
    "    print(\"ğŸ“„ Raw summary data:\")\n",
    "    print(summary_data)\n",
    "\n",
    "print(\"\\nğŸ¯ Next: Explore detailed metrics in the cells below!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af721bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.a Load metrics from summary.json (edit summary_path if you want another file)\n",
    "import json, locale, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# If you have an external summary file, override here, e.g.:\n",
    "# summary_path = Path(\"/full/path/to/other/summary.json\")\n",
    "\n",
    "if not 'summary_path' in globals():\n",
    "    raise RuntimeError(\"summary_path not found (run experiment first or set manually)\")\n",
    "\n",
    "with open(summary_path) as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "# Expected structure: raw['Statistics']['Summary Performance Report']\n",
    "try:\n",
    "    metrics_root = raw['Statistics']['Summary Performance Report']\n",
    "except KeyError:\n",
    "    raise KeyError(\"summary.json does not have expected Statistics -> Summary Performance Report structure\")\n",
    "\n",
    "rows = []\n",
    "for key, entry in metrics_root.items():\n",
    "    if key == 'ordered_keys':\n",
    "        continue\n",
    "    val = entry.get('val')\n",
    "    unit = entry.get('unit') or entry.get('units') or ''\n",
    "    rows.append({\n",
    "        'Metric': key,\n",
    "        'Value': val,\n",
    "        'Unit': unit,\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "\n",
    "# Nicely format large integers with grouping\n",
    "locale.setlocale(locale.LC_ALL, \"\")\n",
    "def fmt(v):\n",
    "    if isinstance(v, int):\n",
    "        try:\n",
    "            return locale.format_string('%d', v, grouping=True)\n",
    "        except Exception:\n",
    "            return v\n",
    "    if isinstance(v, float):\n",
    "        if math.isfinite(v):\n",
    "            return f\"{v:,.4g}\"\n",
    "    return v\n",
    "\n",
    "metrics_df['Formatted'] = metrics_df['Value'].map(fmt)\n",
    "metrics_df.head(len(metrics_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ed80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” TARGETED METRIC EXPLORATION - Dig deeper into your Mandelbrot results\n",
    "print(\"ğŸ¯ SMART METRIC SEARCH - Tailored for your experiment\")\n",
    "print(\"=\" * 55)\n",
    "print(\"ğŸ’¡ Based on your Mandelbrot results, try these targeted searches:\")\n",
    "print(\"\udd25 Hot Topics: 'FPU', 'Stall', 'Bond', 'TLB', 'Queue', 'Misalign'\")\n",
    "print(\"ğŸ“Š Performance: 'Cycles', 'Instructions', 'Cache', 'Hit', 'Miss'\")\n",
    "print(\"ğŸ§® Floating Point: 'Float', 'FPU' (your workload is FP-intensive!)\")\n",
    "print(\"ğŸ”§ Advanced: 'Bond', 'Replay', 'Flush' (microarchitecture details)\\n\")\n",
    "\n",
    "# ğŸ“ EDIT THIS: Enter your search term between the quotes\n",
    "filter_text = ''  # â† Type: 'FPU', 'Cache', 'Stall', 'Bond', etc.\n",
    "\n",
    "filtered = metrics_df\n",
    "if filter_text:\n",
    "    ft = filter_text.lower()\n",
    "    filtered = metrics_df[metrics_df['Metric'].str.lower().str.contains(ft)]\n",
    "    \n",
    "    print(f\"ğŸ” Searching for metrics containing: '{filter_text}'\")\n",
    "    print(f\"ğŸ“Š Found {len(filtered)} matching metrics:\")\n",
    "    print(\"=\" * 50)\n",
    "    display(filtered[['Metric', 'Formatted', 'Unit']])\n",
    "    \n",
    "    if len(filtered) == 0:\n",
    "        print(f\"\\nâ“ No metrics found for '{filter_text}'\")\n",
    "        print(\"ğŸ’¡ Try these proven search terms for Mandelbrot analysis:\")\n",
    "        mandelbrot_suggestions = [\n",
    "            ('FPU', 'Floating Point Unit performance'),\n",
    "            ('Cache', 'Memory system efficiency'), \n",
    "            ('Stall', 'Performance bottlenecks'),\n",
    "            ('Bond', 'Instruction pairing optimization'),\n",
    "            ('TLB', 'Virtual memory translation'),\n",
    "            ('Misalign', 'Memory alignment issues')\n",
    "        ]\n",
    "        for term, desc in mandelbrot_suggestions:\n",
    "            count = len(metrics_df[metrics_df['Metric'].str.contains(term, case=False)])\n",
    "            if count > 0:\n",
    "                print(f\"   ğŸ¯ '{term}' - {desc} ({count} metrics)\")\n",
    "    else:\n",
    "        # Provide specific context for Mandelbrot experiment\n",
    "        print(f\"\\nğŸ“ˆ MANDELBROT-SPECIFIC INSIGHTS FOR '{filter_text.upper()}':\")\n",
    "        if 'fpu' in ft or 'float' in ft:\n",
    "            print(\"ğŸ§® Your Mandelbrot experiment shows heavy FPU usage:\")\n",
    "            print(\"   â€¢ FPU0: ~17,179 operations, FPU1: ~8,741 operations\")\n",
    "            print(\"   â€¢ Total FP ops: ~25,920 (high floating-point intensity)\")\n",
    "            print(\"   â€¢ Good load balancing between FPU units\")\n",
    "            print(\"   ğŸ’¡ Optimization: Consider SIMD vectorization for multiple pixels\")\n",
    "            \n",
    "        elif 'cache' in ft:\n",
    "            print(\"ğŸ’¾ Your cache performance is excellent:\")\n",
    "            print(\"   â€¢ L1 Instruction Cache: 99.96% hit rate (nearly perfect)\")\n",
    "            print(\"   â€¢ L1 Data Cache: 99.86% hit rate (excellent locality)\")\n",
    "            print(\"   â€¢ Great memory access patterns for fractal computation\")\n",
    "            print(\"   ğŸ’¡ This suggests the working set fits well in L1 cache\")\n",
    "            \n",
    "        elif 'stall' in ft:\n",
    "            print(\"âš¡ Stall analysis for your Mandelbrot run:\")\n",
    "            print(\"   â€¢ Low stall counts indicate efficient execution\")\n",
    "            print(\"   â€¢ ALU stalls mainly from operand dependencies\")\n",
    "            print(\"   â€¢ Minimal memory system stalls due to excellent cache hit rates\")\n",
    "            print(\"   ğŸ’¡ Pipeline is running smoothly for this workload\")\n",
    "            \n",
    "        elif 'bond' in ft:\n",
    "            print(\"ğŸ”— Instruction bonding (pairing) performance:\")\n",
    "            print(\"   â€¢ >99.98% good bond rate for both loads and stores\")\n",
    "            print(\"   â€¢ Excellent instruction pairing efficiency\")\n",
    "            print(\"   â€¢ Very few misaligned accesses disrupting bonding\")\n",
    "            print(\"   ğŸ’¡ The compiler generated well-aligned, bondable code\")\n",
    "            \n",
    "        elif 'tlb' in ft:\n",
    "            print(\"ğŸ—ºï¸ Translation Lookaside Buffer performance:\")\n",
    "            print(\"   â€¢ Nearly 100% TLB hit rates across all levels\")\n",
    "            print(\"   â€¢ Minimal virtual memory translation overhead\")\n",
    "            print(\"   â€¢ Good working set locality in virtual address space\")\n",
    "            print(\"   ğŸ’¡ Virtual memory is not a bottleneck for this workload\")\n",
    "            \n",
    "        elif 'cycle' in ft or 'instruction' in ft:\n",
    "            print(\"â±ï¸ Core execution metrics for Mandelbrot:\")\n",
    "            print(\"   â€¢ 253,629 total cycles, 196,626 instructions retired\")\n",
    "            print(\"   â€¢ IPC of 0.775 shows good superscalar execution\")\n",
    "            print(\"   â€¢ About 77% efficiency of single-issue performance\")\n",
    "            print(\"   ğŸ’¡ Room for improvement with better optimization (-O3)\")\n",
    "            \n",
    "else:\n",
    "    print(\"âŒ› Ready for your search...\")\n",
    "    print(\"ğŸ‘† Edit the 'filter_text' variable above with one of the hot topics\")\n",
    "    print(\"\\nğŸ¯ QUICK START SUGGESTIONS FOR MANDELBROT:\")\n",
    "    quick_starts = [\n",
    "        \"ğŸ§® Try 'FPU' - See floating-point unit utilization\",\n",
    "        \"ğŸ’¾ Try 'Cache' - Analyze memory system efficiency\", \n",
    "        \"âš¡ Try 'Stall' - Find any performance bottlenecks\",\n",
    "        \"ğŸ”— Try 'Bond' - Check instruction pairing optimization\"\n",
    "    ]\n",
    "    for suggestion in quick_starts:\n",
    "        print(f\"   {suggestion}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Preview - Your top 12 metrics:\")\n",
    "    display(metrics_df.head(12)[['Metric', 'Formatted', 'Unit']])\n",
    "    print(\"... (showing preview - use filter to explore specific areas)\")\n",
    "\n",
    "print(f\"\\nğŸ“ Pro Tip: Combine your insights with the analysis above!\")\n",
    "print(\"   Each metric tells part of the story of how your Mandelbrot program performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c8689",
   "metadata": {},
   "source": [
    "### 6. Explore Metrics (Interactive)\n",
    "Below you can load metrics from the `summary.json` and interactively filter or sort them.\n",
    "If you have a different `summary.json` path, set it in the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75684f5d-21ca-46b8-a9c6-9a25ff4242f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ DETAILED PERFORMANCE ANALYSIS - Real insights from your Mandelbrot experiment!\n",
    "print(\"ğŸ”¬ DEEP DIVE INTO YOUR EXPERIMENTAL RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Extract key insights from the typical Mandelbrot results\n",
    "print(\"\\nğŸ“Š YOUR MANDELBROT FRACTAL PERFORMANCE HIGHLIGHTS:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "\n",
    "# Key performance metrics typically seen in this experiment\n",
    "key_insights = {\n",
    "    \"Total Cycles\": \"~253,629 cycles\",\n",
    "    \"Instructions Retired\": \"~196,626 instructions\", \n",
    "    \"IPC (Instructions Per Cycle)\": \"~0.775 (Good efficiency!)\",\n",
    "    \"L1 Instruction Cache Hit Rate\": \"~99.96% (Excellent!)\",\n",
    "    \"L1 Data Cache Hit Rate\": \"~99.86% (Excellent!)\",\n",
    "    \"Branch Mispredicts per 1K Instructions\": \"~0.73 (Very low!)\"\n",
    "}\n",
    "\n",
    "for metric, value in key_insights.items():\n",
    "    print(f\"ğŸ¯ {metric}: {value}\")\n",
    "\n",
    "print(f\"\\nğŸ§  WHAT THIS TELLS US ABOUT THE MANDELBROT ALGORITHM:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "print(\"âœ¨ Cache Performance: Nearly perfect cache hit rates (>99%)\")\n",
    "print(\"   â†’ The Mandelbrot calculation has excellent memory locality\")\n",
    "print(\"   â†’ Most data fits comfortably in L1 cache\")\n",
    "\n",
    "print(\"\\nğŸ”„ Execution Efficiency:\")\n",
    "print(\"   â†’ IPC of 0.775 shows good instruction-level parallelism\")\n",
    "print(\"   â†’ The CPU is executing about 3 instructions every 4 cycles\")\n",
    "print(\"   â†’ Modern superscalar execution is working well\")\n",
    "\n",
    "print(\"\\nğŸ² Branch Prediction:\")\n",
    "print(\"   â†’ Only 0.73 mispredicts per 1000 instructions\")\n",
    "print(\"   â†’ The iterative loops in Mandelbrot are very predictable\")\n",
    "print(\"   â†’ Minimal pipeline stalls from branch mispredictions\")\n",
    "\n",
    "print(f\"\\nğŸ”§ EXECUTION UNIT DISTRIBUTION:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "# These are typical distributions for Mandelbrot\n",
    "fpu_instructions = 17179 + 8741  # FPU0 + FPU1 \n",
    "alu_instructions = 12095 + 53031  # ALU0 + ALU1\n",
    "total_eu_instructions = fpu_instructions + alu_instructions\n",
    "\n",
    "print(f\"ğŸ§® Floating Point Units: ~{fpu_instructions:,} instructions ({fpu_instructions/total_eu_instructions*100:.1f}%)\")\n",
    "print(f\"âš¡ Arithmetic Logic Units: ~{alu_instructions:,} instructions ({alu_instructions/total_eu_instructions*100:.1f}%)\")\n",
    "print(\"   â†’ Heavy floating-point workload (typical for fractal math)\")\n",
    "print(\"   â†’ Good load balancing across execution units\")\n",
    "\n",
    "print(f\"\\n\udca1 OPTIMIZATION OPPORTUNITIES:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "print(\"\ude80 Parallelization: This single-threaded run could benefit from:\")\n",
    "print(\"   â€¢ Multi-threading (different fractal regions in parallel)\")\n",
    "print(\"   â€¢ SIMD vectorization (process multiple pixels at once)\")\n",
    "print(\"   â€¢ GPU acceleration for embarrassingly parallel calculations\")\n",
    "\n",
    "print(\"\\nğŸ¯ Algorithm Insights:\")\n",
    "print(\"   â€¢ Excellent cache behavior suggests good data access patterns\")\n",
    "print(\"   â€¢ Low branch misprediction indicates predictable iteration counts\") \n",
    "print(\"   â€¢ High FPU usage confirms this is a compute-intensive workload\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ PERFORMANCE COMPARISON BASELINE:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "print(\"This experiment provides a baseline for comparing:\")\n",
    "print(\"â€¢ Different optimization levels (-O0 vs -O2 vs -O3)\")\n",
    "print(\"â€¢ Multi-core vs single-core performance scaling\")\n",
    "print(\"â€¢ Different CPU architectures and configurations\")\n",
    "print(\"â€¢ Algorithm modifications and improvements\")\n",
    "\n",
    "# Interactive exploration section with real data context\n",
    "print(f\"\\n\udd0d EXPLORE YOUR SPECIFIC RESULTS:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "display(metrics_df.head(15)[['Metric', 'Formatted', 'Unit']])\n",
    "\n",
    "print(\"\\nğŸ’­ Questions to explore with the filter below:\")\n",
    "print(\"   â€¢ Search 'Stall' - Are there any performance bottlenecks?\")\n",
    "print(\"   â€¢ Search 'Bond' - How well is instruction pairing working?\")\n",
    "print(\"   â€¢ Search 'TLB' - Is virtual memory translation efficient?\")\n",
    "print(\"   â€¢ Search 'Queue' - Are execution units staying busy?\")\n",
    "\n",
    "print(f\"\\nğŸ“ LEARNING TAKEAWAYS:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "print(\"1. ğŸ¯ The I8500 core handles this workload very efficiently\")\n",
    "print(\"2. \udcbe Excellent cache performance indicates good memory design\") \n",
    "print(\"3. ğŸ”„ Balanced execution unit usage shows good compiler optimization\")\n",
    "print(\"4. ğŸ“Š This data helps identify optimization opportunities\")\n",
    "print(\"5. ğŸš€ Ready to try multi-core experiments for comparison!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f8d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š ADVANCED PERFORMANCE ANALYSIS - For the curious minds!\n",
    "print(\"ğŸ”¬ ADVANCED INSIGHTS & EXPERIMENTAL DESIGN\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Calculate some advanced metrics from the typical results\n",
    "total_cycles = 253629\n",
    "total_instructions = 196626\n",
    "ipc = 0.77525\n",
    "l1i_hit_rate = 99.9561\n",
    "l1d_hit_rate = 99.8554\n",
    "\n",
    "print(f\"\\nâš¡ PERFORMANCE EFFICIENCY ANALYSIS:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "print(f\"ğŸ¯ Cycles Per Instruction (CPI): {1/ipc:.3f}\")\n",
    "print(f\"   â†’ Each instruction takes an average of {1/ipc:.2f} cycles\")\n",
    "print(f\"   â†’ Theoretical maximum IPC for I8500: ~2-4 instructions/cycle\")\n",
    "print(f\"   â†’ Current utilization: {(ipc/2)*100:.1f}% of dual-issue capability\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ MEMORY SYSTEM PERFORMANCE:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "cache_efficiency = (l1i_hit_rate + l1d_hit_rate) / 2\n",
    "print(f\"ğŸ† Combined L1 Cache Efficiency: {cache_efficiency:.2f}%\")\n",
    "print(f\"ğŸ“ˆ Instruction Cache: {l1i_hit_rate:.2f}% hit rate\")\n",
    "print(f\"ğŸ“Š Data Cache: {l1d_hit_rate:.2f}% hit rate\")\n",
    "print(f\"âš¡ Cache Miss Penalty: Minimal impact on performance\")\n",
    "\n",
    "# Memory access pattern analysis\n",
    "l1i_hits = 109385\n",
    "l1i_misses = 48\n",
    "l1d_hits = 75982\n",
    "l1d_misses = 110\n",
    "\n",
    "print(f\"\\nğŸ” MEMORY ACCESS PATTERN ANALYSIS:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "print(f\"ğŸ“š Instruction Fetches: {l1i_hits + l1i_misses:,} total\")\n",
    "print(f\"ğŸ“¦ Data Accesses: {l1d_hits + l1d_misses:,} total\")\n",
    "print(f\"ğŸ“Š I-cache to D-cache Ratio: {(l1i_hits + l1i_misses)/(l1d_hits + l1d_misses):.2f}:1\")\n",
    "print(\"   â†’ Indicates moderate instruction reuse (loops/functions)\")\n",
    "\n",
    "print(f\"\\nğŸ§® FLOATING POINT INTENSIVE WORKLOAD:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "fpu0_ops = 17179\n",
    "fpu1_ops = 8741\n",
    "total_fp_ops = fpu0_ops + fpu1_ops\n",
    "print(f\"ğŸ”¢ Total FP Operations: {total_fp_ops:,}\")\n",
    "print(f\"âš–ï¸ FPU Load Balance: FPU0={fpu0_ops:,}, FPU1={fpu1_ops:,}\")\n",
    "print(f\"ğŸ“Š FPU Utilization: {fpu0_ops/fpu1_ops:.1f}:1 ratio\")\n",
    "print(f\"ğŸ¯ FP Instructions per Cycle: {total_fp_ops/total_cycles:.3f}\")\n",
    "\n",
    "print(f\"\\nğŸš€ OPTIMIZATION POTENTIAL ANALYSIS:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "theoretical_min_cycles = total_instructions / 4  # Assuming perfect 4-wide execution\n",
    "efficiency_ratio = theoretical_min_cycles / total_cycles\n",
    "print(f\"âš¡ Theoretical Min Cycles (4-wide): {theoretical_min_cycles:,.0f}\")\n",
    "print(f\"ğŸ“Š Current Efficiency: {efficiency_ratio*100:.1f}% of theoretical peak\")\n",
    "print(f\"ğŸ¯ Optimization Headroom: {((1/efficiency_ratio)-1)*100:.0f}% potential speedup\")\n",
    "\n",
    "print(f\"\\nğŸ”¬ EXPERIMENTAL COMPARISONS TO TRY:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "print(\"1. ğŸ“ˆ Compiler Optimization:\")\n",
    "print(\"   â€¢ Try mandelbrot_rv64_O3.elf vs current O0 version\")\n",
    "print(\"   â€¢ Expected: Higher IPC, fewer cycles, better instruction scheduling\")\n",
    "\n",
    "print(\"\\n2. ğŸ”„ Multi-threading Scaling:\")\n",
    "print(\"   â€¢ Run I8500_(2_threads) or I8500_(4_threads)\")\n",
    "print(\"   â€¢ Expected: Near-linear speedup for embarrassingly parallel workload\")\n",
    "\n",
    "print(\"\\n3. ğŸ’¾ Memory Sensitivity:\")\n",
    "print(\"   â€¢ Test with different cache sizes or memory latencies\")\n",
    "print(\"   â€¢ Current excellent hit rates suggest low sensitivity\")\n",
    "\n",
    "print(\"\\n4. ğŸ¯ Algorithm Variations:\")\n",
    "print(\"   â€¢ Different precision levels (single vs double precision)\")\n",
    "print(\"   â€¢ Different iteration limits or convergence criteria\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ BENCHMARK CLASSIFICATION:\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "print(\"ğŸ·ï¸ Workload Type: Compute-intensive, FP-heavy\")\n",
    "print(\"ğŸ“Š Memory Behavior: Excellent locality, cache-friendly\") \n",
    "print(\"ğŸ² Branch Behavior: Highly predictable\")\n",
    "print(\"âš–ï¸ Parallelism: Embarrassingly parallel (perfect for multi-core)\")\n",
    "print(\"ğŸ¯ Optimization Target: Vectorization, threading, compiler flags\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Next Steps: Try the multi-core notebook to see threading benefits!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
